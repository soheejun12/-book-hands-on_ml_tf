{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Your First Graph and Running It in a Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전체적인 실행과정\n",
    "#### 그래프(플로우차트) 생성 --> 실행(Session, run) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 그래프 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#그래프 만들기 \n",
    "#노드 생성 \n",
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "\n",
    "f = x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 실행(돌리기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "#가장 기초적이고 기본적인 방법 1\n",
    "\n",
    "#Session 만들기 \n",
    "sess = tf.Session()\n",
    "\n",
    "#.run :실제 실행\n",
    "#.initializer : 초기화 \n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "\n",
    "result = sess.run(f)\n",
    "print(result)\n",
    "\n",
    "#닫아줘야함 \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "#with 구문을 사용한 방법 2\n",
    "\n",
    "#with 블록의 세션은 기본 세션으로 설정됨 \n",
    "with tf.Session() as sess : \n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "    \n",
    "print(result)\n",
    "    \n",
    "# f.eval = tf.get_default_session().run(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "#가장 짧은 방법 3\n",
    "\n",
    "init = tf.global_variables_initializer() #init node를 준비 \n",
    "\n",
    "with tf.Session() as sess :\n",
    "    init.run() #한 번에 노드 초기화 (실제)\n",
    "    result = f.eval()\n",
    "    \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "# 방법 4\n",
    "\n",
    "sess = tf.InteractiveSession() #자동으로 기본 세션이 생성됨 (with블록 필요 X)\n",
    "init.run()\n",
    "result = f.eval()\n",
    "\n",
    "print(result)\n",
    "\n",
    "sess.close() #수동으로 닫아줘야 함 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow 프로그램은 일반적으로 두 부분으로 나뉨 \n",
    "#### - construction phase : 계산 그래프 빌드 -- 일반적으로 ML 모델과 그것을 학습시키기 위해 필요한 계산을 나타내는 그래프 빌드 \n",
    "#### - execution phase : 실행 -- 학습을 반복적으로 평가하는 루프를 실행하여 점진적으로 모델 파라미터 향상 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Managing Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#아무런 설정이 없다면 노드는 기본적으로 default_graph(기본 그래프)에 생성됨 \n",
    "\n",
    "x1 = tf.Variable(1)\n",
    "\n",
    "x1.graph is tf.get_default_graph() #x1 그래프는 default_graph에서 가져올 수 있는가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#그래프 설정 \n",
    "\n",
    "graph = tf.Graph() #graph라는 이름의 텐서플로우 그래프 생성 \n",
    "\n",
    "with graph.as_default(): #graph를 default로 노드 생성 \n",
    "    x2 = tf.Variable(2)\n",
    "    \n",
    "x2.graph is graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is tf.get_default_graph() #default_graph에서 가져올 수 없다 (존재하지 않음 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 많은 중복 노드를 포함하는 기본 그래프가 생성될 경우 \n",
    "- Jupyter 커널 재시작 \n",
    "- tf,reset_default_graph() 실행  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lifecycle of a Node Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 노드 평가 시, 텐서플로우는 의존적인 노드 집합을 자동으로 결정하고 그 노드를 먼저 평가함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "W = tf.constant(3)#상수 설정 \n",
    "x = W + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "init.run()\n",
    "\n",
    "print(y.eval())\n",
    "print(z.eval())\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "#위와 동일한 작업 (with구문 사용)\n",
    "\n",
    "#그래프 빌드 \n",
    "W = tf.constant(3)\n",
    "x = W + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "#실행 \n",
    "with tf.Session() as sess:\n",
    "    print(y.eval())\n",
    "    print(z.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tensorflow는 자동으로 y는 x에 의존적이라는 것을 감지함 \n",
    "    - y 평가 시 - 처음에 W 평가, 그 다음 x 평가, 그 다음 y 평가 후 y값 반환 \n",
    "    - z 평가 시 - 처음에 W 평가, 그 다음 x 평가, 그 다음 z 평가 후 z값 반환 \n",
    "\n",
    "\n",
    "- 이전 평가 결과를 다시 사용하지 않음\n",
    "    - W와 x를 두 번 계산 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "#W, x가 두 번 평가되지 않도록 \n",
    "\n",
    "#그래프 빌드 \n",
    "W = tf.constant(3)\n",
    "x = W +2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "#실행 \n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "init.run()\n",
    "y_val, z_val = sess.run([y, z])\n",
    "\n",
    "print(y_val)\n",
    "print(z_val)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "#위와 동일한 작업 (with구문 사용)\n",
    "\n",
    "#그래프 빌드 \n",
    "W = tf.constant(3)\n",
    "\n",
    "x = W + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "#실행 \n",
    "with tf.Session() as sess:\n",
    "    y_val, z_val = sess.run([y, z])\n",
    "    print(y_val)\n",
    "    print(z_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflow operations(ops)는 임의의 수의 입력값을 가져와서 여러개의 출력값을 생성할 수 있음 \n",
    "### 입력과 출력은 tensor라고 하는 다차원 배열 \n",
    "#### - Numpy 배열과 마찬가지로 tensor는 type과 shape을 가짐 \n",
    "#### - 일반적으로 부동 소수점을 포함하지만 문자열을 전달할 때도 사용 가능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -3.74651413e+01]\n",
      " [  4.35734153e-01]\n",
      " [  9.33829229e-03]\n",
      " [ -1.06622010e-01]\n",
      " [  6.44106984e-01]\n",
      " [ -4.25131839e-06]\n",
      " [ -3.77322501e-03]\n",
      " [ -4.26648885e-01]\n",
      " [ -4.40514028e-01]]\n"
     ]
    }
   ],
   "source": [
    "#2장의 캘리포니아 주택 데이터 세트 사용하여 선형 회귀 수행 \n",
    "#폐쇄방정식을 사용하여 최적의 세타값 구하기 \n",
    "\n",
    "import numpy as np \n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "m, n = housing.data.shape\n",
    "#모든 학습 데이터에 bias(X0=1)을 추가 \n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data] #세타0은 늘 1\n",
    "\n",
    "#그래프 빌드 \n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "XT = tf.transpose(X)#전치\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y) #세타의 정ㅇ의 정규방정식(4장) \n",
    "\n",
    "#실행 \n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "    \n",
    "print(theta_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE =  4.55993\n",
      "Epoch 100 MSE =  0.709479\n",
      "Epoch 200 MSE =  0.631835\n",
      "Epoch 300 MSE =  0.605129\n",
      "Epoch 400 MSE =  0.585716\n",
      "Epoch 500 MSE =  0.571203\n",
      "Epoch 600 MSE =  0.5603\n",
      "Epoch 700 MSE =  0.552076\n",
      "Epoch 800 MSE =  0.545843\n",
      "Epoch 900 MSE =  0.541097\n",
      "[[ 2.06855249]\n",
      " [ 0.88613427]\n",
      " [ 0.15806651]\n",
      " [-0.31858847]\n",
      " [ 0.32595119]\n",
      " [ 0.00906561]\n",
      " [-0.04385704]\n",
      " [-0.56022257]\n",
      " [-0.53485698]]\n"
     ]
    }
   ],
   "source": [
    "#경사하강법 (Batch Gradient Descent) 사용하여 최적의 세타값 구하기 \n",
    "\n",
    "#Manually Computing the Gradients\n",
    "#1. 수동으로 경사 계산\n",
    "\n",
    "#정규화 --> Gradient Descent 사용 시, 정규화를 하지 않으면 학습이 느려질 수 있음 \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]\n",
    "\n",
    "n_epochs = 1000 #주기 \n",
    "learning_rate = 0.01\n",
    "\n",
    "#그래프 빌드 \n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1], -1.0, 1.0), name='theta') \n",
    "#tf.random_uniorm(shape, 시작, 끝 범위) : 무작위 값을 포함하는 텐서 생성 \n",
    "y_pred = tf.matmul(X, theta, name='prediction')\n",
    "\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error) #기울기계산 \n",
    "#mse 미분(?)\n",
    "\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "#assign() : 새로운 값을 변수에 할당 할 노드 생성, Batch Gradient Descent step 구현 \n",
    "#theta에 저 연산 값을 넣는다 \n",
    "#일종의 업데이트라 파악하자\n",
    "\n",
    "#실행\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0: #100주기마다 출력\n",
    "            print('Epoch', epoch, 'MSE = ', mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval() #mse가 최소가되는 세타값\n",
    "\n",
    "print(best_theta)\n",
    "#매 반복마다 MSE가 줄어듦 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE =  5.6655\n",
      "Epoch 100 MSE =  0.753876\n",
      "Epoch 200 MSE =  0.637803\n",
      "Epoch 300 MSE =  0.605272\n",
      "Epoch 400 MSE =  0.582707\n",
      "Epoch 500 MSE =  0.566445\n",
      "Epoch 600 MSE =  0.554714\n",
      "Epoch 700 MSE =  0.546251\n",
      "Epoch 800 MSE =  0.540145\n",
      "Epoch 900 MSE =  0.53574\n",
      "[[ 2.06855226]\n",
      " [ 0.78212601]\n",
      " [ 0.145603  ]\n",
      " [-0.10891832]\n",
      " [ 0.14678352]\n",
      " [ 0.00588153]\n",
      " [-0.04058502]\n",
      " [-0.7487449 ]\n",
      " [-0.71063733]]\n"
     ]
    }
   ],
   "source": [
    "#Using autodiff\n",
    "#2. tf의 autodiff로 자동으로 gradient 계산 \n",
    "#자동으로 효율적인 gradient 계산 가능 \n",
    "\n",
    "n_epochs = 1000 #주기 \n",
    "learning_rate = 0.01\n",
    "\n",
    "#그래프 빌드 \n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1], -1.0, 1.0), name='theta') #tf.random_uniorm(shape, 시작, 끝 범위)\n",
    "y_pred = tf.matmul(X, theta, name='prediction')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "\n",
    "gradients =tf.gradients(mse, [theta])[0]\n",
    "#tf.gradients() : op(여기서는 mse)와 변수 목록(theta)를 취하고 \n",
    "                  #각 op에 대한 op의 기울기를 계산하기위해 하나의 변수 당 하나의 ops 목록을 만듦\n",
    "                  #gradient 노드는 theta에 관한 mse의 gradient 벡터를 계산함\n",
    "                  #tf.gradients(목적함수, 매개변수)\n",
    "\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "#실행\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0: #100주기마다 출력\n",
    "            print('Epoch', epoch, 'MSE = ', mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval() #mse가 최소가되는 세타값\n",
    "\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE =  4.42048\n",
      "Epoch 100 MSE =  0.671789\n",
      "Epoch 200 MSE =  0.596169\n",
      "Epoch 300 MSE =  0.577517\n",
      "Epoch 400 MSE =  0.564692\n",
      "Epoch 500 MSE =  0.555147\n",
      "Epoch 600 MSE =  0.54798\n",
      "Epoch 700 MSE =  0.542573\n",
      "Epoch 800 MSE =  0.538476\n",
      "Epoch 900 MSE =  0.535354\n",
      "[[ 2.06855249]\n",
      " [ 0.87551254]\n",
      " [ 0.15063265]\n",
      " [-0.30869892]\n",
      " [ 0.32224935]\n",
      " [ 0.00649875]\n",
      " [-0.0430016 ]\n",
      " [-0.62438238]\n",
      " [-0.5982731 ]]\n"
     ]
    }
   ],
   "source": [
    "#Using an Optimizer\n",
    "#3. tf의 gradient descent optimizer 사용하기  \n",
    "\n",
    "n_epochs = 1000 #주기 \n",
    "learning_rate = 0.01\n",
    "\n",
    "#그래프 빌드 \n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1], -1.0, 1.0), name='theta') #tf.random_uniorm(shape, 시작, 끝 범위)\n",
    "y_pred = tf.matmul(X, theta, name='prediction')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse') \n",
    "gradients =tf.gradients(mse, [theta])[0]\n",
    "\n",
    "#최적기 \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    " \n",
    "training_op = optimizer.minimize(mse) #mse를 최소화하는것이 목적, 목적함수만 넘겨줌  \n",
    "    \n",
    "#실행\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0: #100주기마다 출력\n",
    "            print('Epoch', epoch, 'MSE = ', mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval() #mse가 최소가되는 세타값\n",
    "\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feeding Data to the Training Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.  7.  8.]]\n",
      "\n",
      "[[  9.  10.  11.]\n",
      " [ 12.  13.  14.]]\n"
     ]
    }
   ],
   "source": [
    "#placeholder노드 : 실제로 계산을 수행하지 않음 - 런타임 시 출력하도록 지정한 데이터만 출력\n",
    "# : 일반적으로 학습 중에 tensorflow에 학습 데이터를 전달하는 데에 사용 \n",
    "A = tf.placeholder(dtype=tf.float32, shape=(None, 3)) #None = any size \n",
    "#A에 들어올 데이터는 2차원, _행3열의 크기어여야 함 \n",
    "B = A + 5\n",
    "\n",
    "with tf.Session() as sess :\n",
    "    B_val_1 = B.eval(feed_dict={A:[[1, 2, 3]]})\n",
    "    B_val_2 = B.eval(feed_dict={A:[[4, 5, 6], [7, 8, 9]]})\n",
    "    \n",
    "print(B_val_1) #A에 1, 2, 3을 넣었을 때의 B평가\n",
    "print(\"\")\n",
    "print(B_val_2)#A에 4, 5, 6 / 7, 8, 9를 넣었을 떄의 B평가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Mini Batch Gradient 구현하기 \n",
    "\n",
    "#그래프생성 \n",
    "#placeholder노드 사용 \n",
    "X = tf.placeholder(dtype=tf.float32, shape=(None, n+1), name='X')\n",
    "y = tf.placeholder(dtype=tf.float32, shape=(None, 1), name='y')\n",
    "\n",
    "batch_size = 100 \n",
    "n_batches = int(np.ceil(m / batch_size)) #batch의 전체 개수 \n",
    "\n",
    "def fetch_batch(epoch, batch_index, bath_size):\n",
    "    np.random.seed(epoch * n_batches +  batch_index)\n",
    "    indices = np.random.randint(m, size=batch_size) #쪼개기\n",
    "    X_batch = scaled_housing_data_plus_bias[indices]\n",
    "    y_batch = housing.target.reshape(-1, 1)[indices]\n",
    "    return X_batch, y_batch\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X : X_batch, y: y_batch}) #batch를 하나씩 실행 \n",
    "            \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.06855249]\n",
      " [ 0.82963324]\n",
      " [ 0.11875443]\n",
      " [-0.26555082]\n",
      " [ 0.30571571]\n",
      " [-0.00450222]\n",
      " [-0.03932687]\n",
      " [-0.89985287]\n",
      " [-0.87050968]]\n"
     ]
    }
   ],
   "source": [
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 17 23 20 60 34 69 46  9 30]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "y = np.random.randint(100, size=10)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Restoring Models\n",
    "\n",
    "- 모델 학습 후 파라미터를 디스크에 저장하여 필요할 때 불러와 사용 혹은 비교할 수 있도록 \n",
    "- 학습 도중 일정한 간격으로 체크포인트를 저장하여 컴퓨터가 다운되었을 때, 마지막 체크포인트부터 진행될 수 있도록 \n",
    "\n",
    "#### 1) 모든 변수 노드 생성 후 construction phase 마지막 부분에 Saver 노드 생성 \n",
    "#### 2) execution phase에서 체크 포인트 파일의 세션과 경로를 전달하여 모델을 저장할 떄 마다 save() 메소드 호출 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE =  6.26354\n",
      "Epoch 100 MSE =  0.748867\n",
      "Epoch 200 MSE =  0.571974\n",
      "Epoch 300 MSE =  0.553418\n",
      "Epoch 400 MSE =  0.545078\n",
      "Epoch 500 MSE =  0.539356\n",
      "Epoch 600 MSE =  0.535235\n",
      "Epoch 700 MSE =  0.532252\n",
      "Epoch 800 MSE =  0.530092\n",
      "Epoch 900 MSE =  0.528524\n",
      "[[ 2.06855249]\n",
      " [ 0.81631893]\n",
      " [ 0.13714455]\n",
      " [-0.20133014]\n",
      " [ 0.23542912]\n",
      " [ 0.00235965]\n",
      " [-0.04059832]\n",
      " [-0.77828342]\n",
      " [-0.74550068]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000 #주기 \n",
    "learning_rate = 0.01\n",
    "\n",
    "#그래프 빌드 \n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1], -1.0, 1.0), name='theta') \n",
    "y_pred = tf.matmul(X, theta, name='prediction')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error) #기울기계산 \n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "#실행\n",
    "init = tf.global_variables_initializer()\n",
    "#Saver 노드 \n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0: #100주기마다 출력\n",
    "            print('Epoch', epoch, 'MSE = ', mse.eval())\n",
    "            save_path = saver.save(sess, '/Users/jsh/1 project/세미나;/tensor_tmp/my_model.cpkt')\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval() \n",
    "    save_path = saver.save(sess, '/Users/jsh/1 project/세미나;/tensor_tmp/my_model.cpkt')\n",
    "\n",
    "print(best_theta)\n",
    "#매 반복마다 MSE가 줄어듦 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/jsh/1 project/세미나;/tensor_tmp/my_model.cpkt\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /Users/jsh/1 project/세미나;/tensor_tmp/my_model.cpkt\n\t [[Node: save_1/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2_1/tensor_names, save_1/RestoreV2_1/shape_and_slices)]]\n\nCaused by op 'save_1/RestoreV2_1', defined at:\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-17-38ce45a4596b>\", line 17, in <module>\n    saver = tf.train.Saver()\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1218, in __init__\n    self.build()\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 751, in _build_internal\n    restore_sequentially, reshape)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 427, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 267, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1020, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /Users/jsh/1 project/세미나;/tensor_tmp/my_model.cpkt\n\t [[Node: save_1/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2_1/tensor_names, save_1/RestoreV2_1/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /Users/jsh/1 project/세미나;/tensor_tmp/my_model.cpkt\n\t [[Node: save_1/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2_1/tensor_names, save_1/RestoreV2_1/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-8a62def6cc2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#exexution phase 시작부분에 init 노드를 이용해 변수 초기화 대신, Saver 객체의 restore()메소드 호출\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'/Users/jsh/1 project/세미나;/tensor_tmp/my_model.cpkt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mbest_theta_restored\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1664\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1665\u001b[0m       sess.run(self.saver_def.restore_op_name,\n\u001b[1;32m-> 1666\u001b[1;33m                {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[0;32m   1667\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_eager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1334\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1336\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /Users/jsh/1 project/세미나;/tensor_tmp/my_model.cpkt\n\t [[Node: save_1/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2_1/tensor_names, save_1/RestoreV2_1/shape_and_slices)]]\n\nCaused by op 'save_1/RestoreV2_1', defined at:\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-17-38ce45a4596b>\", line 17, in <module>\n    saver = tf.train.Saver()\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1218, in __init__\n    self.build()\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 751, in _build_internal\n    restore_sequentially, reshape)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 427, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 267, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1020, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /Users/jsh/1 project/세미나;/tensor_tmp/my_model.cpkt\n\t [[Node: save_1/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2_1/tensor_names, save_1/RestoreV2_1/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "#모델 재생성 \n",
    "#construction phase 끝에 Saver노드 생성 후 \n",
    "#exexution phase 시작부분에 init 노드를 이용해 변수 초기화 대신, Saver 객체의 restore()메소드 호출 \n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, '/Users/jsh/1 project/세미나;/tensor_tmp/my_model.cpkt')\n",
    "    best_theta_restored = theta.eval()\n",
    "    \n",
    "print(best_theta_restored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Graph and Training Curves Using TensorBoard\n",
    "\n",
    "#### 그래프에서 오류를 식별하고 병목 현상을 찾는 등의 작업에 유용 \n",
    "\n",
    "#### 1) 텐서보드가 읽을 로그 디렉토리에 그래프 정의 및 학습통계를 기록 \n",
    "- 프로그램을 실행할 때마다 다른 로그 디렉토리를 사용해야 함 (섞일 수가 있음)\n",
    "    - 로그 디렉토리에 timestamp를 포함시키면 중복을 막을 수 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#timestamp\n",
    "#프로그램 시작 부분에 이 코드 추가 \n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f3e24a59752e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"X\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"theta\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n' is not defined"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f50b2dc2ab1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmse_summary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'MSE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfile_writer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mse' is not defined"
     ]
    }
   ],
   "source": [
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:                                                        # not shown in the book\n",
    "    sess.run(init)                                                                # not shown\n",
    "\n",
    "    for epoch in range(n_epochs):                                                 # not shown\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "    # not shown\n",
    "    \n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Name Scopes \n",
    "\n",
    "#### 많은 노드들로 복잡해 지는 것을 막기 위해 이름 범위를 만들어 관련 노드를 그룹화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loss라는 이름 범위 내에서 error와 mse 정의 \n",
    "with tf.name_scope(\"loss\") as scope:\n",
    "    error = y_pred - y\n",
    "    mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "    \n",
    "with tf.Session() as sess:                                                        # not shown in the book\n",
    "    sess.run(init)                                                                # not shown\n",
    "\n",
    "    for epoch in range(n_epochs):                                                 # not shown\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "    # not shown\n",
    "    \n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss/sub\n"
     ]
    }
   ],
   "source": [
    "#범위 내에 정의 된 각 op의 앞에는 지정된 이름(loss)이 붙음 \n",
    "#텐서보드에서는 loss안에 error와 mse노드가 숨겨져 있음 -- loss 노드의 플러스버튼을 누르면 확인 가능 \n",
    "print(error.op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss/mse\n"
     ]
    }
   ],
   "source": [
    "print(mse.op.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modularity\n",
    "\n",
    "- 두 개의 ReLU의 출력을 더하는 그래프 생성하기 \n",
    "    - ReLU : 입력의 선형함수를 계산하고 양수이면 결과를 출력, 양수가 아니면 0을 출력 (후에 더 다룰 예정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "\n",
    "#가중치와 바이어스 \n",
    "w1 = tf.Variable(tf.random_normal((n_features, 1)), name=\"weights1\")\n",
    "w2 = tf.Variable(tf.random_normal((n_features, 1)), name=\"weights2\")\n",
    "b1 = tf.Variable(0.0, name=\"bias1\")\n",
    "b2 = tf.Variable(0.0, name=\"bias2\")\n",
    "\n",
    "z1 = tf.add(tf.matmul(X, w1), b1, name=\"z1\")\n",
    "z2 = tf.add(tf.matmul(X, w2), b2, name=\"z2\")\n",
    "\n",
    "relu1 = tf.maximum(z1, 0., name=\"relu1\")\n",
    "relu2 = tf.maximum(z2, 0., name=\"relu2\")  \n",
    "\n",
    "output = tf.add(relu1, relu2, name=\"output\")\n",
    "\n",
    "#이렇게 반복적인 코드는 유지가 어려우며 오류가 발생하기 쉬움 \n",
    "#Tensorflow를 통해 DRY 상태를 유지할 수 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#간단하게 ReLU를 만드는 함수 생성 \n",
    "#5개의 ReLU를 만들고 합계를 출력하는 코드 \n",
    "def relu(X):\n",
    "    w_shape = (int(X.get_shape()[1]), 1)\n",
    "    w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
    "    b = tf.Variable(0.0, name=\"bias\")\n",
    "    z = tf.add(tf.matmul(X, w), b, name=\"z\")\n",
    "    return tf.maximum(z, 0., name=\"relu\")\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")\n",
    "#add_n() : 텐서 목록의 합계를 계산하는 연산을 만듦 \n",
    "\n",
    "#노드 생성 시 tensorflow는 해당 이름이 이미 있는지 확힌하고, 고유성을 위해 이름에 밑줄을 추가함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Name scope 사용 \n",
    "def relu(X):\n",
    "    with tf.name_scope(\"relu\"):#변수들을 name scope 내로 이동 \n",
    "        w_shape = (int(X.get_shape()[1]), 1)\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
    "        b = tf.Variable(0.0, name=\"bias\")\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")\n",
    "        return tf.maximum(z, 0., name=\"relu\")\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")\n",
    "\n",
    "file_writer = tf.summary.FileWriter(\"logs/relu2\", tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharing Variables \n",
    "\n",
    "- 그래프의 다양한 컴포넌트 사이에서 변수를 공유하려면, 간단한 함수를 작성하고 필요로 하는 함수에 파라미터를 전달하면 됨 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
