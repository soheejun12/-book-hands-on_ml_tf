{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 10. Inroduction to Artificial Neural Networks\n",
    "\n",
    "### 인간 뇌의 연구는 인공신경망(ANN)에게 영감을 준 핵심아이디어 \n",
    "### ANN은 딥러닝의 핵심 \n",
    "#### - ANN의 장점 \n",
    "- 다목적(versatile)\n",
    "- 강력(powerful))\n",
    "- 좋은 확장성(scalable)\n",
    "\n",
    "\n",
    "#### - ANN의 활용 사례 \n",
    "- 이미지 분류 (구글 이미지)\n",
    "- 음성 인식 서비스 (애플 siri)\n",
    "- 영상 추천 (유튜브)\n",
    "- 자가 대결을 통한 게임 학습(알파고)\n",
    "\n",
    "\n",
    "\n",
    "### 이번 장에서는 \n",
    "- 최초의 ANN 구조를 간력히 살펴보고 인공신경망에 대한 소개 \n",
    "- MLP 소개 후 텐서플로우를 통해 MNIST 숫자 분류 문제 해결 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Biological to Artificial Neurons \n",
    "#### ANN은 꽤 오랫동안 주변에 있었음 \n",
    "#### - 최초의 인공신경망(ANN) 구조\n",
    "- 1943년 등장 \n",
    "- 명제논리학(propositional logic)을 사용\n",
    "- 생물학적 뉴런이 동물 뇌에서 작동하여 복잡한 계산을 수행하는 방법에 대한 간단한 모델 제시\n",
    "\n",
    "\n",
    "#### - ANN의 역사 \n",
    "- 1960년대의 초기 성공은 곧 지능을 가진 기계와 진정으로 대화할 수 있을 것이라는 믿을 줌 \n",
    "- 하지만 불확실한 상황이 지속되자 어두운 시대로 도래됨 \n",
    "- 1980년대 초에 새로운 구조들이 발명되고 더 나은 학습기법이 개발되면서 ANN에 대한 관심이 살아남 \n",
    "- 하지만 1990년대 SVM과 같은 다른 강력한 기계학습 기술이 더 좋은 결과와 더 강력한 이론적 토대를 제공하는 것 처럼 보여 대부분의 연구자가 선호하게 됨 \n",
    "- 현재 ANN은 다시 주목을 받고 있으며 앞으로 ANN이 더 발전될 것을 기대하는 이유 \n",
    "    - 현존하는 방대한 양의 데이터를 활용해 신경망 학습이 가능 \n",
    "        - ANN은 매우 크고 복잡한 문제에 다른 기계학습 기법보다 더 우수한 성능을 보임 \n",
    "    - 1990년대 이래로 크게 발전한 컴퓨팅 능력으로 합리적인 시간에 대규모 신경 네트워크 학습 가능 \n",
    "    - 학습 알고리즘의 개선\n",
    "    - ANN의 이론적 한계 중 일부분은 양성(benign)으로 밝혀짐\n",
    "    - ANN 기반 제품은 정기적으로 주목받고 있음 \n",
    "     \n",
    "     \n",
    "### Biological Neurons \n",
    "#### - 생물학적 뉴런 \n",
    "<img src = \"image\\ch10\\neuron.png\">\n",
    "- 동물의 대뇌피질에서 발견되는 드문 세포 \n",
    "- 세포핵(nucleus), 세포체(cell body), 수상돌기(dendrite), 축색돌기(axon)등으로 구성 \n",
    "- 축색돌기는 말단 근처에서 축삭끝가지(telodendria)로 쪼개짐 \n",
    "- 축삭끝가지의 끝에는 다른 뉴런의 수상돌기와 연결된 시냅스(synaptic terminals)가 있음 \n",
    "- 생물학적 뉴런은 시냅스를 통해 다른 뉴런의 신호(signal)인 짧은 전기적 자극을 받음 \n",
    "- 수 밀리 초 이내에 뉴런이 다른 뉴런으로부터 충분한 수의 신호를 수신하면 자신의 신호를 작동(fire)시킴 \n",
    "- 복잡한 계산이라도 단순한 뉴런의 광대한 네트워크를 통해 수행 가능 \n",
    "<img src = \"image\\ch10\\neuron2.png\">\n",
    "- 생물학적 신경망(BNN)의 구조는 여전히 활발하게 연구가 진행되는 중이지만 뇌의 일부분은 매핑되어 있으며 뉴런은 연속적인 계층으로 구성되는 것처럼 보임  \n",
    "\n",
    "\n",
    "### Logical Computations with Neurons\n",
    "#### - 단순한 생물학적 뉴런 모델 \n",
    "- 단순한 모델을 사용해도 원하는 모든 논리적 명제를 계산하는 ANN구축이 가능하다는 것을 보여줌 \n",
    "- 후에 인공 뉴런으로 알려지게 됨 \n",
    "- 하나 이상의 이진(ON/OFF)입력과 이진출력을 가짐 \n",
    "- 특정 수 이상의 입력이 활성화 되었을 때 출력을 활성화\n",
    "\n",
    "\n",
    "#### - 예)\n",
    "- 두 개 이상의 입력이 활성화되었을 때 뉴런이 활성화 된다 가정 \n",
    "- 다양한 논리 연산을 수행하는 ANN \n",
    "<img src = \"image\\ch10\\simple.png\">\n",
    "- 1) 간단한 항등함수. A가 활성화되면 C도 활성화 됨 \n",
    "    - 뉴런 A로부터 두 개의 입력신호를 받음 \n",
    "    - A가 비활성화이면 C도 비활성화 \n",
    "\n",
    "\n",
    "- 2) 논리적 AND 수행. C는 A, B가 모두 활성화 되었을 때만 활성화 됨 \n",
    "    - 활성화를 위해서는 두 개 이상의 입력신호가 필요 \n",
    "   \n",
    "   \n",
    "- 3) 논리적 OR 수행. C는 A 또는 B가 활성화 되었을 때, A와 B모두 활성화 되었을 때 활성화 됨 \n",
    "- 4) 입력 연결이 뉴런의 활동을 억제할 수 있다고 가정 \n",
    "    - C는 A가 활성화, B가 비활성화일 때 활성화 됨 \n",
    "    - A가 항상 활성화되어있으면 논리적 NOT을 얻음 \n",
    "        - B가 비활성화일 때 c는 활성화 됨 (A의 입력신호는 두 개)\n",
    "        - 역도 성립 \n",
    "        \n",
    "     \n",
    "- 이러한 네트워크를 결합하여 복잡한 논리 표현식도 계산할 수 있음 \n",
    "\n",
    "\n",
    "### The Perceptron \n",
    "#### - 1957년 등장한 가장 단순한 ANN 구조 중 하나 \n",
    "#### - 선형 임계값 단위(LTU)를 기반으로 함 \n",
    "<img src = \"image\\ch10\\perceptron.png\">\n",
    "- 입력과 출력은 이진이 아닌 숫자\n",
    "- 입력연결은 가중치와 연결 됨 \n",
    "- LTU는 입력의 가중된 합을 계산한 후 그 합에 step function을 적용하여 결과를 출력 \n",
    "- 퍼셉트론에서 가장 일반적으로 사용하는 step function은 heaviside 함수 (때때로 sign함수를 사용하기도 함)\n",
    "<img src = \"image\\ch10\\heaviside.png\">\n",
    "\n",
    "- 단순 선형 이진 분류에 단일 LTU를 사용할 수 있음 \n",
    "    - 입력의 선형 조합을 계산하고 결과가 임계값을 초과하면 양수클래스를 출력, 그렇지 않으면 음수클래스 출력 \n",
    "    \n",
    "    \n",
    "- LTU를 학습시키는 것은 w0, w1, w2 (가중치)에 대한 올바른 값을 찾는 것을 의미 \n",
    "    - 학습 알고리즘에 대해서는 뒤에서 설명 \n",
    "    \n",
    "#### - 구성  \n",
    "- 퍼셉트론은 LTU의 단일층으로 구성 \n",
    "- 모든 입력은 각 뉴런과 연결됨(input neuron)\n",
    "- 보통 바이어스 특징도 추가됨 (X0=1) (bias neuron)\n",
    "\n",
    "#### - 예)\n",
    "<img src = \"image\\ch10\\perceptron2.png\">\n",
    "- 두개의 입력과 세개의 출력을 갖는 퍼셉트론 \n",
    "- 다중 출력 분류기 \n",
    "\n",
    "\n",
    "#### - 학습 \n",
    "- 헵 규칙(Hebb's rule)에 영향을 받음 \n",
    "    - 두 뉴런이 동일한 출력을 가질 때 마다 두 뉴런 사이의 연결 가중치는 증가한다 \n",
    "\n",
    "\n",
    "- 퍼셉트론은 한 번에 하나의 데이터를 받으며 각 데이터에 대해 예측을 함 \n",
    "- 틀린 예측을 생산한 모든 출력 뉴런에 대해 올바른 예측을 할 수 있도록 연결 가중치를 강화함\n",
    "- 퍼셉트론의 가중치 업데이트 \n",
    "<img src = \"image\\ch10\\perceptron3.png\">\n",
    "\n",
    "\n",
    "    - wij : i번째 입력뉴런과 j번째 출력 뉴런 사이의 연결 가중치 \n",
    "    - xi : 학습 데이터의 i번째 입력값 \n",
    "    - y^j : j번째 출력뉴런의 출력값 (예측값)\n",
    "    - yj : j번째 출력 뉴런의 타겟값\n",
    "    - 에타 : 학습률 \n",
    "    \n",
    "\n",
    "- 각 출력뉴런의 결정경계는 선형 \n",
    "    - 그러므로 퍼셉트론은 복잡한 패턴을 학습할 수 없음 \n",
    "    \n",
    "    \n",
    "- 하지만 학습 데이터가 선형으로 분류될 수 있다면 이 알고리즘이 해결책이 될 수 있음 (perceptron convergence theorem)\n",
    "\n",
    "- Scikit-learn에서 단일 LTU 네트워크를 구현하는 Perceptron클래스 제공 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### - Scikit-learn에서 제공하는 단일 LTU 네트워크를 구현하는 Perceptron클래스로 iris 데이터 분류하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "#데이터 불러오기 \n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "print(iris.feature_names)\n",
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 꽃받침 길이, 꽃받침 넓이, 꽃잎 길이, 꽃잎 넓이를 속성으로 갖음 \n",
    "- 클래스는 setosa(0), versicolor(1), virginica(2)로 구성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dtools\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "X = iris.data[:, (2, 3)]  #꽃잎 길이, 꽃잎 넓이 \n",
    "y = (iris.target == 0).astype(np.int) #타겟이 0(setosa)이면 1, 아니면 0\n",
    "\n",
    "#퍼셉트론 \n",
    "per_clf = Perceptron(random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "#새로운 데이터예측 \n",
    "y_pred = per_clf.predict([[2, 0.5]])\n",
    "\n",
    "print(y_pred) #새로운 데이터의 예측 클래스는 1(versicolor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0]\n"
     ]
    }
   ],
   "source": [
    "y = (iris.target == 0).astype(np.int)\n",
    "print(iris.target)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 퍼셉트론 학습 알고리즘은 Stochastic Gradient Descent와 매우 유사함 \n",
    "    - 실제로 sicikt-learn의 Perceptron클래스는 SGDClassifier에서 파라미터를 loss='perceptron', learning_rate='constant', eta0=1, penalty=None로 사용한것과 같음 \n",
    "    \n",
    "    \n",
    "- 퍼셉트론은 선형회귀분류기와 달리 클래스 확률을 출력하지 않음 \n",
    "    - 단지 임계값을 기반으로 예측을 수행함 \n",
    "    - 그렇기 때문에 퍼셉트론보다 로지스틱회귀가 더 선호됨 \n",
    "    \n",
    "  \n",
    "#### - 한계 \n",
    "- 퍼셉트론의 약점은 Exclusive OR(XOR) 분류문제를 해결 할 수 없다는 것 \n",
    "<img src = \"image\\ch10\\xor2.png\">\n",
    "<img src = \"image\\ch10\\xor.png\">\n",
    "\n",
    "- 이러한 약점으로 신경망 연구가 중단되었음 \n",
    "\n",
    "\n",
    "#### - 해결 \n",
    "- 여러개의 퍼셉트론을 쌓은(stacking) 퍼셉트론인 MLP를 통해 한계점 중 부분을 해결 \n",
    "- 특히 MLP의 출력을 계산하여 확인할 수 있기 때문에 XOR 문제 해결 가능 \n",
    "- 입력 (0, 0), (1, 1)은 0을 출력, 입력 (0, 1), (1, 0)은 1을 출력\n",
    "\n",
    "\n",
    "### Multi-Layer Perceptron and Backpropagation \n",
    "#### - 구성 \n",
    "<img src = \"image\\ch10\\mlp.png\">\n",
    "- MLP는 하나의 입력 레이어, LTU로 구성된 하나 이상의 은닉 레이어, LTU로 구성된 하나의 출력 레이어로 구성 \n",
    "- 출력 레이어를 제외한 모든 레이어는 bias 뉴런을 포함하며, 다음 레이어에 완전 연결됨 (fully connected)\n",
    "- ANN에 두 개 이상의 은닉 레이어가 있으면 DNN(Deep Neural Network)이라 함 \n",
    "\n",
    "\n",
    "#### - 역전파 학습 알고리즘 (backpropagation training algorithm)\n",
    "- 알고리즘은 각 데이터를 네트워크에 전달하고 각 연속 레이어의 모든 뉴런의 출력을 연산 (예측 시와 마찬가지로 순방향(forward)전달)\n",
    "- 네트워크의 출력오차(예측값과 타겟값의 차이)를 측정\n",
    "- 마지막 은닉레이어의 각 뉴런이 각각의 출력뉴런의 오차에 얼마나 기여했는지 계산 \n",
    "- 그 다음 그 이전 은닉레이어의 각 뉴런이 오차에 얼마나 기여했는지 계산 \n",
    "- 입력레이어에 도달할 때까지 진행 \n",
    "- 이러한 역방향 전달은 네크워크에서 역방향으로 오차 기울기(error gradient)를 전파함으로써 네트워크의 모든 연결 가중치에 대한 오차 기울기를 효율적으로 측정함 \n",
    "- 역전파 알고리즘의 마지막 단계는 측정한 오차 기울기를 사용하여 네트워크의 모든 연결 가중치에 대한 Graient Descent 수행 (가중치 업데이트)\n",
    "\n",
    "- 즉 \n",
    "    - 역전파 알고리즘은 각각의 학습 데이터에 대해 예측을 수행하고, 오류 측정 후, 역방향으로 각 레이어를 거쳐 각 연결에서의 error 기여도를 측정하고, 마지막으로 error를 줄이기 위해 연결가중치를 미세하게 조정하는 것 \n",
    "    \n",
    "#### - step function \n",
    "- 역전파 알고리즘 수행을 위해 저자는 MLP의 구조를 변경함 \n",
    "    - step function을 Logistic function [σ (z) = 1 / (1 + exp (-z))] 으로 대체 \n",
    "        - logistic function : S자형의 연속적인 함수, 출력값의 범위는 0 ~ 1\n",
    "    - 기울기 하강법을 수행하기 위해 (기울기 하강법은 평평한 곳에서 수행할 수 없음)\n",
    "  \n",
    "  \n",
    "- logistic function외의 다른 활성화 함수 \n",
    "<img src = \"image\\ch10\\af.png\">\n",
    "    - The hyperbolic tangent function tanh\n",
    "        - S자형이며 연속적\n",
    "        - 미분 가능하지만 출력값의 범위는 -1 ~ 1 \n",
    "        - 학습 초기에 각 레이어의 출력이 대략적으로 정규화되는 경향이 있음 (수렴 속도 향상에 도움을 줌)\n",
    "    - The ReLU function (9장에서 소개)\n",
    "        - 연속적 \n",
    "        - 하지만 z=0일 때 미분할 수 없음 (기울기가 갑자기 변해서 gradient descent가 튕길 수 있음)\n",
    "        - 실제로는 잘 작동하며 계산속도가 빠름 \n",
    "        - 최대 출력값이 정해져있지 않아 gradient descent등의 일부 문제를 줄이는데 도움을 줌 (11장에서 설명)\n",
    "        \n",
    "        \n",
    "#### - FNN 예시 \n",
    "- MLP는 종종 분류에 사용되며 각 출력은 이진 클래스에 해당함 \n",
    "- 클래스들이 배타적일 때는 일반적으로 출력 레이어의 개별 활성화 함수를 softmax함수로 대체함 \n",
    "    - softmax 함수 : 각 클래스에 속할 확률을 계산 \n",
    "<img src = \"image\\ch10\\mlp2.png\">\n",
    "- 각 뉴런의 출력은 해당 클래스의 예상 확률이 됨 \n",
    "- 신호는 입력에서 출력으로, 한 방향으로만 흐름 \n",
    "    - 그러므로 이 구조는 FNN의 예 \n",
    "    \n",
    "    \n",
    "#### ※\n",
    "- 생물학적 뉴런은 대략 sigmoid(S자 형태)활성화 함수를 따르는것 처럼 보여 연구원들은 오랫동안 sigmoid 함수를 고수했었음 \n",
    "- 하지만 ANN에서 일반적으로 ReLU 활성화 함수가 더 잘 동작하는 것으로 밝혀짐 \n",
    "    - 생물학적 유추로 인한 오해의 예 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an MLP with Tensorflow's High-Level API \n",
    "#### - 텐서플로우를 통해 MLP를 학습하는 가장 간단한 방법은 scikit-learn의 API와 비슷한 고레벨 API인 TF.Learn을 사용하는 것 \n",
    "- DNNClassifier 클래스를 사용하면 여러 개의 은닉레이어를 사용하여 DNN을 쉽게 학습할 수 있으며 예상 클래스 확률을 출력할 수 있는 softmax 출력 레이어를 생성할 수 있음 \n",
    "\n",
    "#### - 두 개의 은닉레이어 (은닉레이어1의 뉴런은 300개, 은닉레이어 2의 뉴런은 100개)와 10개의 뉴런을 가진 softmax 출력 레이어로 구성된 DNN 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#MNIST 데이터 불러오기 \n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "\n",
    "X_train = mnist.train.images\n",
    "X_test = mnist.test.images\n",
    "y_train = mnist.train.labels.astype(\"int\")\n",
    "y_test = mnist.test.labels.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ymk\\AppData\\Local\\Temp\\tmpx81_5_4p\n",
      "INFO:tensorflow:Using config: {'_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_num_worker_replicas': 0, '_is_chief': True, '_environment': 'local', '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_save_checkpoints_steps': None, '_save_summary_steps': 100, '_model_dir': 'C:\\\\Users\\\\ymk\\\\AppData\\\\Local\\\\Temp\\\\tmpx81_5_4p', '_task_type': None, '_save_checkpoints_secs': 600, '_session_config': None, '_log_step_count_steps': 100, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001965F2F6208>, '_keep_checkpoint_max': 5, '_num_ps_replicas': 0}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\ymk\\AppData\\Local\\Temp\\tmpx81_5_4p\\model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 2.35613\n",
      "INFO:tensorflow:global_step/sec: 399.979\n",
      "INFO:tensorflow:step = 101, loss = 0.36538 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.823\n",
      "INFO:tensorflow:step = 201, loss = 0.270191 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.962\n",
      "INFO:tensorflow:step = 301, loss = 0.465652 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.243\n",
      "INFO:tensorflow:step = 401, loss = 0.232789 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.101\n",
      "INFO:tensorflow:step = 501, loss = 0.239315 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.256\n",
      "INFO:tensorflow:step = 601, loss = 0.0763566 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.426\n",
      "INFO:tensorflow:step = 701, loss = 0.141446 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.631\n",
      "INFO:tensorflow:step = 801, loss = 0.236211 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.503\n",
      "INFO:tensorflow:step = 901, loss = 0.113399 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.806\n",
      "INFO:tensorflow:step = 1001, loss = 0.210421 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.161\n",
      "INFO:tensorflow:step = 1101, loss = 0.20864 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.737\n",
      "INFO:tensorflow:step = 1201, loss = 0.134749 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.091\n",
      "INFO:tensorflow:step = 1301, loss = 0.18093 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.336\n",
      "INFO:tensorflow:step = 1401, loss = 0.0639534 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.615\n",
      "INFO:tensorflow:step = 1501, loss = 0.0821855 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.524\n",
      "INFO:tensorflow:step = 1601, loss = 0.150339 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.085\n",
      "INFO:tensorflow:step = 1701, loss = 0.0360158 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.59\n",
      "INFO:tensorflow:step = 1801, loss = 0.158557 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.315\n",
      "INFO:tensorflow:step = 1901, loss = 0.084028 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.258\n",
      "INFO:tensorflow:step = 2001, loss = 0.0706866 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.828\n",
      "INFO:tensorflow:step = 2101, loss = 0.0311902 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.745\n",
      "INFO:tensorflow:step = 2201, loss = 0.0247898 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.097\n",
      "INFO:tensorflow:step = 2301, loss = 0.038971 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.935\n",
      "INFO:tensorflow:step = 2401, loss = 0.0605455 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.452\n",
      "INFO:tensorflow:step = 2501, loss = 0.084688 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 581.742\n",
      "INFO:tensorflow:step = 2601, loss = 0.0527992 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.602\n",
      "INFO:tensorflow:step = 2701, loss = 0.034881 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.957\n",
      "INFO:tensorflow:step = 2801, loss = 0.0450113 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.447\n",
      "INFO:tensorflow:step = 2901, loss = 0.0971271 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.226\n",
      "INFO:tensorflow:step = 3001, loss = 0.0273951 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.684\n",
      "INFO:tensorflow:step = 3101, loss = 0.0526358 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.104\n",
      "INFO:tensorflow:step = 3201, loss = 0.0112531 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.592\n",
      "INFO:tensorflow:step = 3301, loss = 0.0341159 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.829\n",
      "INFO:tensorflow:step = 3401, loss = 0.257467 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.103\n",
      "INFO:tensorflow:step = 3501, loss = 0.081647 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.405\n",
      "INFO:tensorflow:step = 3601, loss = 0.163458 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.656\n",
      "INFO:tensorflow:step = 3701, loss = 0.0512237 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.681\n",
      "INFO:tensorflow:step = 3801, loss = 0.00944292 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.604\n",
      "INFO:tensorflow:step = 3901, loss = 0.065656 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.886\n",
      "INFO:tensorflow:step = 4001, loss = 0.158834 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 533.516\n",
      "INFO:tensorflow:step = 4101, loss = 0.0266167 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.899\n",
      "INFO:tensorflow:step = 4201, loss = 0.0562069 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.541\n",
      "INFO:tensorflow:step = 4301, loss = 0.16992 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.433\n",
      "INFO:tensorflow:step = 4401, loss = 0.116732 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.51\n",
      "INFO:tensorflow:step = 4501, loss = 0.0156275 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.626\n",
      "INFO:tensorflow:step = 4601, loss = 0.0154021 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.523\n",
      "INFO:tensorflow:step = 4701, loss = 0.0168122 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.79\n",
      "INFO:tensorflow:step = 4801, loss = 0.0208337 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.981\n",
      "INFO:tensorflow:step = 4901, loss = 0.0613998 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.951\n",
      "INFO:tensorflow:step = 5001, loss = 0.0683717 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.958\n",
      "INFO:tensorflow:step = 5101, loss = 0.00509645 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 640.413\n",
      "INFO:tensorflow:step = 5201, loss = 0.026127 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.917\n",
      "INFO:tensorflow:step = 5301, loss = 0.0188427 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.149\n",
      "INFO:tensorflow:step = 5401, loss = 0.102891 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.369\n",
      "INFO:tensorflow:step = 5501, loss = 0.0364312 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.105\n",
      "INFO:tensorflow:step = 5601, loss = 0.0840275 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.934\n",
      "INFO:tensorflow:step = 5701, loss = 0.0154911 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.875\n",
      "INFO:tensorflow:step = 5801, loss = 0.0118759 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.629\n",
      "INFO:tensorflow:step = 5901, loss = 0.0875156 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.164\n",
      "INFO:tensorflow:step = 6001, loss = 0.128454 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.631\n",
      "INFO:tensorflow:step = 6101, loss = 0.0196943 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.611\n",
      "INFO:tensorflow:step = 6201, loss = 0.017003 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.223\n",
      "INFO:tensorflow:step = 6301, loss = 0.0623537 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.531\n",
      "INFO:tensorflow:step = 6401, loss = 0.0230785 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.959\n",
      "INFO:tensorflow:step = 6501, loss = 0.0211821 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.72\n",
      "INFO:tensorflow:step = 6601, loss = 0.00502701 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 582.154\n",
      "INFO:tensorflow:step = 6701, loss = 0.0272443 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.377\n",
      "INFO:tensorflow:step = 6801, loss = 0.00689532 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.638\n",
      "INFO:tensorflow:step = 6901, loss = 0.00921277 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.278\n",
      "INFO:tensorflow:step = 7001, loss = 0.0398338 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.639\n",
      "INFO:tensorflow:step = 7101, loss = 0.00151812 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.564\n",
      "INFO:tensorflow:step = 7201, loss = 0.0598629 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.304\n",
      "INFO:tensorflow:step = 7301, loss = 0.00624156 (0.266 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 457.084\n",
      "INFO:tensorflow:step = 7401, loss = 0.0120557 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.266\n",
      "INFO:tensorflow:step = 7501, loss = 0.00441273 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.622\n",
      "INFO:tensorflow:step = 7601, loss = 0.0334218 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.309\n",
      "INFO:tensorflow:step = 7701, loss = 0.0122204 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.85\n",
      "INFO:tensorflow:step = 7801, loss = 0.00312656 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.835\n",
      "INFO:tensorflow:step = 7901, loss = 0.00690873 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.409\n",
      "INFO:tensorflow:step = 8001, loss = 0.00278175 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 533.303\n",
      "INFO:tensorflow:step = 8101, loss = 0.0177011 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.957\n",
      "INFO:tensorflow:step = 8201, loss = 0.0125759 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.244\n",
      "INFO:tensorflow:step = 8301, loss = 0.0592631 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.591\n",
      "INFO:tensorflow:step = 8401, loss = 0.0185081 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.691\n",
      "INFO:tensorflow:step = 8501, loss = 0.00393315 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.306\n",
      "INFO:tensorflow:step = 8601, loss = 0.00234619 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.384\n",
      "INFO:tensorflow:step = 8701, loss = 0.00295271 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.316\n",
      "INFO:tensorflow:step = 8801, loss = 0.0173992 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.844\n",
      "INFO:tensorflow:step = 8901, loss = 0.00252102 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.641\n",
      "INFO:tensorflow:step = 9001, loss = 0.0140142 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.521\n",
      "INFO:tensorflow:step = 9101, loss = 0.00633414 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.674\n",
      "INFO:tensorflow:step = 9201, loss = 0.00774336 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.971\n",
      "INFO:tensorflow:step = 9301, loss = 0.00663732 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.322\n",
      "INFO:tensorflow:step = 9401, loss = 0.0458651 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.587\n",
      "INFO:tensorflow:step = 9501, loss = 0.0075188 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.652\n",
      "INFO:tensorflow:step = 9601, loss = 0.00371499 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.311\n",
      "INFO:tensorflow:step = 9701, loss = 0.010792 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.272\n",
      "INFO:tensorflow:step = 9801, loss = 0.00397466 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.8\n",
      "INFO:tensorflow:step = 9901, loss = 0.0255376 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.212\n",
      "INFO:tensorflow:step = 10001, loss = 0.0127354 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 581.998\n",
      "INFO:tensorflow:step = 10101, loss = 0.00312975 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.229\n",
      "INFO:tensorflow:step = 10201, loss = 0.00958452 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.627\n",
      "INFO:tensorflow:step = 10301, loss = 0.00445756 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.652\n",
      "INFO:tensorflow:step = 10401, loss = 0.0346505 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.601\n",
      "INFO:tensorflow:step = 10501, loss = 0.0061844 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.973\n",
      "INFO:tensorflow:step = 10601, loss = 0.00690333 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.086\n",
      "INFO:tensorflow:step = 10701, loss = 0.0129873 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.092\n",
      "INFO:tensorflow:step = 10801, loss = 0.0153129 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.813\n",
      "INFO:tensorflow:step = 10901, loss = 0.00235802 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.956\n",
      "INFO:tensorflow:step = 11001, loss = 0.0336028 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.514\n",
      "INFO:tensorflow:step = 11101, loss = 0.00761013 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.966\n",
      "INFO:tensorflow:step = 11201, loss = 0.000985124 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.806\n",
      "INFO:tensorflow:step = 11301, loss = 0.00883439 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.958\n",
      "INFO:tensorflow:step = 11401, loss = 0.00616294 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.791\n",
      "INFO:tensorflow:step = 11501, loss = 0.0236959 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.455\n",
      "INFO:tensorflow:step = 11601, loss = 0.000431447 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.953\n",
      "INFO:tensorflow:step = 11701, loss = 0.0037892 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.967\n",
      "INFO:tensorflow:step = 11801, loss = 0.000573102 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.429\n",
      "INFO:tensorflow:step = 11901, loss = 0.00328168 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.526\n",
      "INFO:tensorflow:step = 12001, loss = 0.000294359 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.241\n",
      "INFO:tensorflow:step = 12101, loss = 0.00117013 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.319\n",
      "INFO:tensorflow:step = 12201, loss = 0.0035361 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.383\n",
      "INFO:tensorflow:step = 12301, loss = 0.00568417 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.955\n",
      "INFO:tensorflow:step = 12401, loss = 0.000299066 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.977\n",
      "INFO:tensorflow:step = 12501, loss = 0.00232882 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.869\n",
      "INFO:tensorflow:step = 12601, loss = 0.00247253 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.447\n",
      "INFO:tensorflow:step = 12701, loss = 0.00354415 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.073\n",
      "INFO:tensorflow:step = 12801, loss = 0.0084501 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.538\n",
      "INFO:tensorflow:step = 12901, loss = 0.00321664 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.539\n",
      "INFO:tensorflow:step = 13001, loss = 0.00422579 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.34\n",
      "INFO:tensorflow:step = 13101, loss = 0.00191968 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.134\n",
      "INFO:tensorflow:step = 13201, loss = 0.0025203 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.082\n",
      "INFO:tensorflow:step = 13301, loss = 0.00632828 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.965\n",
      "INFO:tensorflow:step = 13401, loss = 0.0123506 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.429\n",
      "INFO:tensorflow:step = 13501, loss = 0.0131242 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.511\n",
      "INFO:tensorflow:step = 13601, loss = 0.00564458 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.757\n",
      "INFO:tensorflow:step = 13701, loss = 0.00180567 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.923\n",
      "INFO:tensorflow:step = 13801, loss = 0.00508851 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.545\n",
      "INFO:tensorflow:step = 13901, loss = 0.00150185 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.404\n",
      "INFO:tensorflow:step = 14001, loss = 0.00232726 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.004\n",
      "INFO:tensorflow:step = 14101, loss = 0.00790522 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.098\n",
      "INFO:tensorflow:step = 14201, loss = 0.00317382 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.622\n",
      "INFO:tensorflow:step = 14301, loss = 0.00254721 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.427\n",
      "INFO:tensorflow:step = 14401, loss = 0.000921343 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.631\n",
      "INFO:tensorflow:step = 14501, loss = 0.000655669 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.7\n",
      "INFO:tensorflow:step = 14601, loss = 0.00604021 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.782\n",
      "INFO:tensorflow:step = 14701, loss = 0.0010195 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.341\n",
      "INFO:tensorflow:step = 14801, loss = 0.000673522 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 533.572\n",
      "INFO:tensorflow:step = 14901, loss = 0.00249339 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.366\n",
      "INFO:tensorflow:step = 15001, loss = 0.000744319 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.261\n",
      "INFO:tensorflow:step = 15101, loss = 0.00297134 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.273\n",
      "INFO:tensorflow:step = 15201, loss = 0.00124015 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.434\n",
      "INFO:tensorflow:step = 15301, loss = 0.00147383 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.618\n",
      "INFO:tensorflow:step = 15401, loss = 0.00144029 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.234\n",
      "INFO:tensorflow:step = 15501, loss = 0.00532294 (0.188 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 399.974\n",
      "INFO:tensorflow:step = 15601, loss = 0.00327829 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.727\n",
      "INFO:tensorflow:step = 15701, loss = 0.00587794 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.571\n",
      "INFO:tensorflow:step = 15801, loss = 0.00133595 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.801\n",
      "INFO:tensorflow:step = 15901, loss = 0.000807929 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.433\n",
      "INFO:tensorflow:step = 16001, loss = 0.00400495 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.127\n",
      "INFO:tensorflow:step = 16101, loss = 0.00268823 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 533.281\n",
      "INFO:tensorflow:step = 16201, loss = 0.000485736 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.521\n",
      "INFO:tensorflow:step = 16301, loss = 0.00421548 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 457\n",
      "INFO:tensorflow:step = 16401, loss = 0.0014356 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.788\n",
      "INFO:tensorflow:step = 16501, loss = 0.00267978 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.958\n",
      "INFO:tensorflow:step = 16601, loss = 0.00217889 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.952\n",
      "INFO:tensorflow:step = 16701, loss = 0.00167899 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.523\n",
      "INFO:tensorflow:step = 16801, loss = 0.00256056 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.545\n",
      "INFO:tensorflow:step = 16901, loss = 0.00318569 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.405\n",
      "INFO:tensorflow:step = 17001, loss = 0.00859974 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.974\n",
      "INFO:tensorflow:step = 17101, loss = 0.00145502 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.964\n",
      "INFO:tensorflow:step = 17201, loss = 0.00357547 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.261\n",
      "INFO:tensorflow:step = 17301, loss = 0.00143041 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.822\n",
      "INFO:tensorflow:step = 17401, loss = 0.00132588 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.546\n",
      "INFO:tensorflow:step = 17501, loss = 0.00184232 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.813\n",
      "INFO:tensorflow:step = 17601, loss = 0.000259764 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.973\n",
      "INFO:tensorflow:step = 17701, loss = 0.000442309 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.63\n",
      "INFO:tensorflow:step = 17801, loss = 0.000382582 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.515\n",
      "INFO:tensorflow:step = 17901, loss = 0.00294985 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.957\n",
      "INFO:tensorflow:step = 18001, loss = 0.000588472 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.431\n",
      "INFO:tensorflow:step = 18101, loss = 0.0010211 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.435\n",
      "INFO:tensorflow:step = 18201, loss = 0.00373705 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.097\n",
      "INFO:tensorflow:step = 18301, loss = 0.0063952 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.602\n",
      "INFO:tensorflow:step = 18401, loss = 0.00376893 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.785\n",
      "INFO:tensorflow:step = 18501, loss = 0.0023639 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.706\n",
      "INFO:tensorflow:step = 18601, loss = 0.00229078 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.641\n",
      "INFO:tensorflow:step = 18701, loss = 0.00118753 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.216\n",
      "INFO:tensorflow:step = 18801, loss = 0.00161144 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.446\n",
      "INFO:tensorflow:step = 18901, loss = 0.00244693 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.829\n",
      "INFO:tensorflow:step = 19001, loss = 0.00130335 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.425\n",
      "INFO:tensorflow:step = 19101, loss = 0.000800225 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.106\n",
      "INFO:tensorflow:step = 19201, loss = 0.000884817 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.424\n",
      "INFO:tensorflow:step = 19301, loss = 0.00766535 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.318\n",
      "INFO:tensorflow:step = 19401, loss = 0.000819972 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.684\n",
      "INFO:tensorflow:step = 19501, loss = 0.00297444 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.13\n",
      "INFO:tensorflow:step = 19601, loss = 0.000644049 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.004\n",
      "INFO:tensorflow:step = 19701, loss = 0.000122361 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.763\n",
      "INFO:tensorflow:step = 19801, loss = 0.000369883 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.926\n",
      "INFO:tensorflow:step = 19901, loss = 0.00123945 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.338\n",
      "INFO:tensorflow:step = 20001, loss = 0.00225148 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.553\n",
      "INFO:tensorflow:step = 20101, loss = 0.000754524 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.528\n",
      "INFO:tensorflow:step = 20201, loss = 0.00234438 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.959\n",
      "INFO:tensorflow:step = 20301, loss = 0.000907093 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.933\n",
      "INFO:tensorflow:step = 20401, loss = 5.85714e-05 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.835\n",
      "INFO:tensorflow:step = 20501, loss = 0.000725217 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.693\n",
      "INFO:tensorflow:step = 20601, loss = 0.000910334 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.24\n",
      "INFO:tensorflow:step = 20701, loss = 0.000593756 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.957\n",
      "INFO:tensorflow:step = 20801, loss = 0.00182575 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.311\n",
      "INFO:tensorflow:step = 20901, loss = 0.000683686 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.881\n",
      "INFO:tensorflow:step = 21001, loss = 0.00209449 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.794\n",
      "INFO:tensorflow:step = 21101, loss = 0.000930309 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.518\n",
      "INFO:tensorflow:step = 21201, loss = 0.00488727 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.365\n",
      "INFO:tensorflow:step = 21301, loss = 0.000983905 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.805\n",
      "INFO:tensorflow:step = 21401, loss = 0.00144944 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.699\n",
      "INFO:tensorflow:step = 21501, loss = 0.000410661 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.963\n",
      "INFO:tensorflow:step = 21601, loss = 0.00044662 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.075\n",
      "INFO:tensorflow:step = 21701, loss = 0.000850109 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.552\n",
      "INFO:tensorflow:step = 21801, loss = 0.000886487 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.485\n",
      "INFO:tensorflow:step = 21901, loss = 0.00057955 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.512\n",
      "INFO:tensorflow:step = 22001, loss = 0.00020022 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.956\n",
      "INFO:tensorflow:step = 22101, loss = 0.000239426 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.085\n",
      "INFO:tensorflow:step = 22201, loss = 0.00147702 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.131\n",
      "INFO:tensorflow:step = 22301, loss = 0.00159259 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.002\n",
      "INFO:tensorflow:step = 22401, loss = 0.0024838 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.133\n",
      "INFO:tensorflow:step = 22501, loss = 0.0013754 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.783\n",
      "INFO:tensorflow:step = 22601, loss = 0.00216801 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.224\n",
      "INFO:tensorflow:step = 22701, loss = 0.000715569 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.738\n",
      "INFO:tensorflow:step = 22801, loss = 0.00115556 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.636\n",
      "INFO:tensorflow:step = 22901, loss = 0.00244842 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.574\n",
      "INFO:tensorflow:step = 23001, loss = 0.000753451 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.436\n",
      "INFO:tensorflow:step = 23101, loss = 0.0032738 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.552\n",
      "INFO:tensorflow:step = 23201, loss = 0.00246872 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.288\n",
      "INFO:tensorflow:step = 23301, loss = 0.00177922 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.655\n",
      "INFO:tensorflow:step = 23401, loss = 0.000950226 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.453\n",
      "INFO:tensorflow:step = 23501, loss = 0.000710965 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.08\n",
      "INFO:tensorflow:step = 23601, loss = 0.000451505 (0.219 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 492.261\n",
      "INFO:tensorflow:step = 23701, loss = 0.000301623 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.616\n",
      "INFO:tensorflow:step = 23801, loss = 0.00164034 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.7\n",
      "INFO:tensorflow:step = 23901, loss = 0.00139234 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.693\n",
      "INFO:tensorflow:step = 24001, loss = 0.00127323 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.476\n",
      "INFO:tensorflow:step = 24101, loss = 0.000666714 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.101\n",
      "INFO:tensorflow:step = 24201, loss = 0.0015628 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.958\n",
      "INFO:tensorflow:step = 24301, loss = 0.000344565 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.952\n",
      "INFO:tensorflow:step = 24401, loss = 0.00217776 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.605\n",
      "INFO:tensorflow:step = 24501, loss = 0.000701962 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.972\n",
      "INFO:tensorflow:step = 24601, loss = 0.000173127 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.437\n",
      "INFO:tensorflow:step = 24701, loss = 0.00044807 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.421\n",
      "INFO:tensorflow:step = 24801, loss = 0.000975899 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.434\n",
      "INFO:tensorflow:step = 24901, loss = 0.000929044 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.524\n",
      "INFO:tensorflow:step = 25001, loss = 0.000367929 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.595\n",
      "INFO:tensorflow:step = 25101, loss = 0.00117167 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.105\n",
      "INFO:tensorflow:step = 25201, loss = 0.00210397 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.439\n",
      "INFO:tensorflow:step = 25301, loss = 0.000566549 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.795\n",
      "INFO:tensorflow:step = 25401, loss = 0.000622293 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.835\n",
      "INFO:tensorflow:step = 25501, loss = 0.000798766 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.586\n",
      "INFO:tensorflow:step = 25601, loss = 0.000718505 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.47\n",
      "INFO:tensorflow:step = 25701, loss = 0.000522906 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.411\n",
      "INFO:tensorflow:step = 25801, loss = 0.00140285 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.528\n",
      "INFO:tensorflow:step = 25901, loss = 0.00181948 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.521\n",
      "INFO:tensorflow:step = 26001, loss = 4.87705e-05 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.545\n",
      "INFO:tensorflow:step = 26101, loss = 0.00113974 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.15\n",
      "INFO:tensorflow:step = 26201, loss = 0.000637599 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.007\n",
      "INFO:tensorflow:step = 26301, loss = 0.000887573 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.808\n",
      "INFO:tensorflow:step = 26401, loss = 0.00146571 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.005\n",
      "INFO:tensorflow:step = 26501, loss = 0.00117383 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.246\n",
      "INFO:tensorflow:step = 26601, loss = 0.000551 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.938\n",
      "INFO:tensorflow:step = 26701, loss = 7.0665e-05 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.129\n",
      "INFO:tensorflow:step = 26801, loss = 0.000419428 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.412\n",
      "INFO:tensorflow:step = 26901, loss = 0.000830283 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.981\n",
      "INFO:tensorflow:step = 27001, loss = 0.000628031 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.802\n",
      "INFO:tensorflow:step = 27101, loss = 0.000652099 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.422\n",
      "INFO:tensorflow:step = 27201, loss = 0.000352462 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.814\n",
      "INFO:tensorflow:step = 27301, loss = 0.000887187 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.431\n",
      "INFO:tensorflow:step = 27401, loss = 0.000180014 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.322\n",
      "INFO:tensorflow:step = 27501, loss = 0.00120429 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.622\n",
      "INFO:tensorflow:step = 27601, loss = 0.000936198 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.253\n",
      "INFO:tensorflow:step = 27701, loss = 0.000286207 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.728\n",
      "INFO:tensorflow:step = 27801, loss = 0.000222911 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.435\n",
      "INFO:tensorflow:step = 27901, loss = 0.000745438 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.255\n",
      "INFO:tensorflow:step = 28001, loss = 0.00115062 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.16\n",
      "INFO:tensorflow:step = 28101, loss = 0.000461974 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.952\n",
      "INFO:tensorflow:step = 28201, loss = 0.0012089 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.431\n",
      "INFO:tensorflow:step = 28301, loss = 0.00072582 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.819\n",
      "INFO:tensorflow:step = 28401, loss = 0.00084309 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.805\n",
      "INFO:tensorflow:step = 28501, loss = 0.00013432 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 533.276\n",
      "INFO:tensorflow:step = 28601, loss = 0.000538351 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 582.105\n",
      "INFO:tensorflow:step = 28701, loss = 0.00102454 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 533.289\n",
      "INFO:tensorflow:step = 28801, loss = 0.00132446 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.396\n",
      "INFO:tensorflow:step = 28901, loss = 0.000368 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.881\n",
      "INFO:tensorflow:step = 29001, loss = 0.00185713 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.512\n",
      "INFO:tensorflow:step = 29101, loss = 0.00117714 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.418\n",
      "INFO:tensorflow:step = 29201, loss = 0.00149311 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.664\n",
      "INFO:tensorflow:step = 29301, loss = 0.00132211 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.076\n",
      "INFO:tensorflow:step = 29401, loss = 0.00109956 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.513\n",
      "INFO:tensorflow:step = 29501, loss = 0.000787965 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.623\n",
      "INFO:tensorflow:step = 29601, loss = 0.000595153 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.274\n",
      "INFO:tensorflow:step = 29701, loss = 0.000503532 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 581.786\n",
      "INFO:tensorflow:step = 29801, loss = 0.000571826 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.806\n",
      "INFO:tensorflow:step = 29901, loss = 0.00101082 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.875\n",
      "INFO:tensorflow:step = 30001, loss = 0.000194199 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.415\n",
      "INFO:tensorflow:step = 30101, loss = 0.000752696 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.141\n",
      "INFO:tensorflow:step = 30201, loss = 0.00026648 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.08\n",
      "INFO:tensorflow:step = 30301, loss = 0.000983529 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.501\n",
      "INFO:tensorflow:step = 30401, loss = 0.00154718 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.786\n",
      "INFO:tensorflow:step = 30501, loss = 0.000452746 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.077\n",
      "INFO:tensorflow:step = 30601, loss = 0.000907597 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.113\n",
      "INFO:tensorflow:step = 30701, loss = 0.00112684 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.431\n",
      "INFO:tensorflow:step = 30801, loss = 0.00114179 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.518\n",
      "INFO:tensorflow:step = 30901, loss = 0.00133285 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.418\n",
      "INFO:tensorflow:step = 31001, loss = 0.00103829 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.957\n",
      "INFO:tensorflow:step = 31101, loss = 0.00107812 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.813\n",
      "INFO:tensorflow:step = 31201, loss = 0.000446936 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.276\n",
      "INFO:tensorflow:step = 31301, loss = 0.000541366 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.311\n",
      "INFO:tensorflow:step = 31401, loss = 0.000738218 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.277\n",
      "INFO:tensorflow:step = 31501, loss = 0.000169803 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.958\n",
      "INFO:tensorflow:step = 31601, loss = 0.000124611 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.537\n",
      "INFO:tensorflow:step = 31701, loss = 0.000874339 (0.187 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 376.425\n",
      "INFO:tensorflow:step = 31801, loss = 0.000284799 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.792\n",
      "INFO:tensorflow:step = 31901, loss = 0.000770105 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.783\n",
      "INFO:tensorflow:step = 32001, loss = 0.000298693 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.133\n",
      "INFO:tensorflow:step = 32101, loss = 0.000360939 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.394\n",
      "INFO:tensorflow:step = 32201, loss = 0.00135265 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 533.341\n",
      "INFO:tensorflow:step = 32301, loss = 0.000533915 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.27\n",
      "INFO:tensorflow:step = 32401, loss = 7.38406e-05 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.273\n",
      "INFO:tensorflow:step = 32501, loss = 0.00050197 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.112\n",
      "INFO:tensorflow:step = 32601, loss = 6.91565e-05 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.564\n",
      "INFO:tensorflow:step = 32701, loss = 0.0013869 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.953\n",
      "INFO:tensorflow:step = 32801, loss = 0.00114328 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.804\n",
      "INFO:tensorflow:step = 32901, loss = 0.00024373 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.877\n",
      "INFO:tensorflow:step = 33001, loss = 0.000567386 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.957\n",
      "INFO:tensorflow:step = 33101, loss = 0.00163544 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.076\n",
      "INFO:tensorflow:step = 33201, loss = 0.000806745 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.115\n",
      "INFO:tensorflow:step = 33301, loss = 0.000108071 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.468\n",
      "INFO:tensorflow:step = 33401, loss = 0.000851157 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.796\n",
      "INFO:tensorflow:step = 33501, loss = 0.000275124 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.444\n",
      "INFO:tensorflow:step = 33601, loss = 0.000630569 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.255\n",
      "INFO:tensorflow:step = 33701, loss = 0.00115286 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 533.274\n",
      "INFO:tensorflow:step = 33801, loss = 0.00100903 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.809\n",
      "INFO:tensorflow:step = 33901, loss = 0.00101929 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 533.581\n",
      "INFO:tensorflow:step = 34001, loss = 0.000753639 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.426\n",
      "INFO:tensorflow:step = 34101, loss = 0.000570717 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.519\n",
      "INFO:tensorflow:step = 34201, loss = 0.00159773 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.451\n",
      "INFO:tensorflow:step = 34301, loss = 0.000429141 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.83\n",
      "INFO:tensorflow:step = 34401, loss = 0.000316816 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.58\n",
      "INFO:tensorflow:step = 34501, loss = 0.000876407 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.406\n",
      "INFO:tensorflow:step = 34601, loss = 0.000380091 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.6\n",
      "INFO:tensorflow:step = 34701, loss = 0.000875513 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.785\n",
      "INFO:tensorflow:step = 34801, loss = 0.00067821 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.241\n",
      "INFO:tensorflow:step = 34901, loss = 0.000672146 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.51\n",
      "INFO:tensorflow:step = 35001, loss = 0.000241702 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.131\n",
      "INFO:tensorflow:step = 35101, loss = 0.000367575 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.426\n",
      "INFO:tensorflow:step = 35201, loss = 0.000316998 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.072\n",
      "INFO:tensorflow:step = 35301, loss = 6.41653e-05 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.635\n",
      "INFO:tensorflow:step = 35401, loss = 0.000960688 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.522\n",
      "INFO:tensorflow:step = 35501, loss = 0.000238609 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.501\n",
      "INFO:tensorflow:step = 35601, loss = 0.000183138 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.53\n",
      "INFO:tensorflow:step = 35701, loss = 0.000885525 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.075\n",
      "INFO:tensorflow:step = 35801, loss = 0.000600627 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.976\n",
      "INFO:tensorflow:step = 35901, loss = 0.000597649 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.947\n",
      "INFO:tensorflow:step = 36001, loss = 0.000411549 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.978\n",
      "INFO:tensorflow:step = 36101, loss = 0.00105188 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.511\n",
      "INFO:tensorflow:step = 36201, loss = 0.000738796 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.632\n",
      "INFO:tensorflow:step = 36301, loss = 0.000159454 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.416\n",
      "INFO:tensorflow:step = 36401, loss = 0.000812505 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.973\n",
      "INFO:tensorflow:step = 36501, loss = 0.000320665 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.298\n",
      "INFO:tensorflow:step = 36601, loss = 0.000252727 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.807\n",
      "INFO:tensorflow:step = 36701, loss = 0.000344234 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.609\n",
      "INFO:tensorflow:step = 36801, loss = 0.000929664 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.102\n",
      "INFO:tensorflow:step = 36901, loss = 0.000538603 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.514\n",
      "INFO:tensorflow:step = 37001, loss = 0.000511412 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.588\n",
      "INFO:tensorflow:step = 37101, loss = 0.000225414 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.428\n",
      "INFO:tensorflow:step = 37201, loss = 0.000275093 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.316\n",
      "INFO:tensorflow:step = 37301, loss = 0.000609382 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.382\n",
      "INFO:tensorflow:step = 37401, loss = 0.000461639 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.844\n",
      "INFO:tensorflow:step = 37501, loss = 0.000176853 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.945\n",
      "INFO:tensorflow:step = 37601, loss = 0.000455153 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.981\n",
      "INFO:tensorflow:step = 37701, loss = 0.000107872 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.639\n",
      "INFO:tensorflow:step = 37801, loss = 0.000335423 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.569\n",
      "INFO:tensorflow:step = 37901, loss = 0.00120914 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.808\n",
      "INFO:tensorflow:step = 38001, loss = 4.56814e-05 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.259\n",
      "INFO:tensorflow:step = 38101, loss = 0.00115053 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.583\n",
      "INFO:tensorflow:step = 38201, loss = 0.000684527 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.601\n",
      "INFO:tensorflow:step = 38301, loss = 6.809e-05 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.266\n",
      "INFO:tensorflow:step = 38401, loss = 0.00015842 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.64\n",
      "INFO:tensorflow:step = 38501, loss = 0.000420868 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.434\n",
      "INFO:tensorflow:step = 38601, loss = 0.000810649 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.061\n",
      "INFO:tensorflow:step = 38701, loss = 0.000556919 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.51\n",
      "INFO:tensorflow:step = 38801, loss = 0.000168285 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.432\n",
      "INFO:tensorflow:step = 38901, loss = 0.00132127 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.611\n",
      "INFO:tensorflow:step = 39001, loss = 0.000147096 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.965\n",
      "INFO:tensorflow:step = 39101, loss = 0.000762992 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.623\n",
      "INFO:tensorflow:step = 39201, loss = 0.000294934 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.423\n",
      "INFO:tensorflow:step = 39301, loss = 0.000161752 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.32\n",
      "INFO:tensorflow:step = 39401, loss = 0.000521355 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.517\n",
      "INFO:tensorflow:step = 39501, loss = 0.000143689 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.862\n",
      "INFO:tensorflow:step = 39601, loss = 0.000740994 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.146\n",
      "INFO:tensorflow:step = 39701, loss = 0.000136613 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.039\n",
      "INFO:tensorflow:step = 39801, loss = 0.00127573 (0.219 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 426.661\n",
      "INFO:tensorflow:step = 39901, loss = 0.00066309 (0.234 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into C:\\Users\\ymk\\AppData\\Local\\Temp\\tmpx81_5_4p\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.000510336.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._MultiClassHead object at 0x000001965A329A58>, 'dropout': None, 'activation_fn': <function relu at 0x00000191DC3D6268>, 'input_layer_min_slice_size': None, 'gradient_clip_norm': None, 'optimizer': None, 'feature_columns': (_RealValuedColumn(column_name='', dimension=784, default_value=None, dtype=tf.float32, normalizer=None),), 'hidden_units': [300, 100], 'embedding_lr_multipliers': None})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "feature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(X_train)\n",
    "#X_train에 대한 특징열 생성 \n",
    "\n",
    "#DNNClassifier 생성 \n",
    "dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[300,100], n_classes=10,\n",
    "                                         feature_columns=feature_cols)\n",
    "\n",
    "dnn_clf.fit(X_train, y_train, batch_size=50, steps=40000)\n",
    "#50개 데이터의 batch 사용, 40000번 반복 학습 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[_RealValuedColumn(column_name='', dimension=784, default_value=None, dtype=tf.float32, normalizer=None)]\n"
     ]
    }
   ],
   "source": [
    "print(feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "feature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(X_train)\n",
    "#X_train에 대한 특징열 생성 \n",
    "\n",
    "#DNNClassifier 생성 \n",
    "dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[300,100], n_classes=10,\n",
    "                                         feature_columns=feature_cols)\n",
    "\n",
    "dnn_clf.fit(feature_cols, y_train, batch_size=50, steps=40000)\n",
    "#50개 데이터의 batch 사용, 40000번 반복 학습 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ymk\\AppData\\Local\\Temp\\tmpx81_5_4p\\model.ckpt-40000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98250000000000004"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = list(dnn_clf.predict(X_test))\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-8442dafa3532>:1: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-16-8442dafa3532>:1: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-09-02:44:55\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ymk\\AppData\\Local\\Temp\\tmpx81_5_4p\\model.ckpt-40000\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-09-02:44:55\n",
      "INFO:tensorflow:Saving dict for global step 40000: accuracy = 0.9825, global_step = 40000, loss = 0.071979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.98250002, 'global_step': 40000, 'loss': 0.071979001}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_clf.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - DNNClassifier\n",
    "- ReLU 활성화 함수를 기반으로 모든 뉴런 레이어를 생성함 (activation_fn 파라미터를 통해 변경 가능)\n",
    "- 출력 레이어는 softmax 활성화함수에 의존 \n",
    "- 비용함수는 교차 엔트로피(cross entropy)사용 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a DNN Using Plain Tensorflow \n",
    "#### - 네트워크 구조를 보다 잘 제어하기 위해서는 텐서플로우의 저레벨 파이썬 API를 사용하는 것이 좋음 \n",
    "#### - 저레벨 API를 사용해 동일한 모델을 만드로 MNIST 데이터 세트에서 Mini-batch Gradient Descent 구현 \n",
    "#### - 첫번째 단계는 그래프를 빌드하는 construction phase\n",
    "#### - 두번째 단계는 실제로 그래프를 실행하여 모델을 학습하는 execution phase \n",
    "\n",
    "\n",
    "### Construction Phase \n",
    "#### - 그래프 빌드하기 \n",
    "- 각 계층의 뉴런 개수 지정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#텐서플로우 라이브러리 불러오기 \n",
    "import tensorflow as tf \n",
    "\n",
    "#입력 레이어의 뉴런 개수는 784개 (MNSIT)\n",
    "#은닉 레이어의 뉴런 개수는 300개, 100개 \n",
    "#출력 레이어의 뉴런 개수는 10개 (0 ~ 9)\n",
    "\n",
    "n_inputs = 28*28  \n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- placeholder 노드를 사용하여 학습데이터와 타겟 설정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이제 실제 신경망을 만들어보자 \n",
    "    - 입력레이어 \n",
    "        - placeholder X는 입력레이어로 작동 : 실행 단계에서 한번에 하나의 학습 batch가 됨 \n",
    "            - 학습 batch의 모든 데이터는 신경망에 의해 동시에 처리됨 \n",
    "    - 두 개의 은닉레이어 \n",
    "        - 두 은닉레이어는 연결되는 입력들과 뉴런의 개수를 제외하고는 거의 동일 \n",
    "    - 출력레이어 \n",
    "        - ReLU 활성화 함수 대신 softmax 활성화 함수 사용 \n",
    "        \n",
    "        \n",
    "- neuron_layer함수 : 하나의 레이어를 만드는 함수 (파라미터로 입력, 뉴런의 개수, 레이어의 이름, 활성화함수를 받음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neuron_layer(X, n_neurons, name, activation=None): \n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1]) #입력의 개수는 입력의 열의 수 \n",
    "        stddev = 2 / np.sqrt(n_inputs) \n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev) #가중치 \n",
    "        W = tf.Variable(init, name=\"kernel\") #가중치\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"bias\") #바이어스(뉴런개수만큼)\n",
    "        Z = tf.matmul(X, W) + b  #입력*가중치+바이어스 \n",
    "        \n",
    "        if activation is not None: #활성화함수가 None이 아니면 Z에 활성화 함수 적용 \n",
    "            return activation(Z)\n",
    "        else: #None이면 Z반환 \n",
    "            return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 위의 코드에 대해 자세히 살펴보자.\n",
    "\n",
    "###### - with tf.name_scope(name):\n",
    "\n",
    " - layer 이름을 사용하여 name scope를 만든다. 이 layer에는 뉴런 layer에 대한 모든 계산 노드가 포함된다. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### - n_inputs = int(X.get_shape()[1])\n",
    "\n",
    "-  다음으로 입력 행렬(input matrix)의 shape에서 열의 개수를 불러와서 input의 수를 얻는다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### - stddev, init, W 부분 (세줄)\n",
    "\n",
    " - 다음 세 줄은 가중치 행렬(weights matrix) (layer's kernel 이라고도 부름)을 hold할 변수 W를 만든다. \n",
    "\n",
    "- 각 입력과 각 뉴런사이의 모든 연결 가중치를 포함하는 2차원 텐서. 따라서 그 모양은 (n_inputs, n_neurons)이 된다. \n",
    "\n",
    "- 절단정규분포로부터의 난수값을 사용하여 무작위로 초기화한다.\n",
    "\n",
    "- 이 특정 표준편차를 사용하면 알고리즘이 훨씬 빨리 수렴하는 데 도움이 된다.(11장에서 더 자세히 논할 예정)\n",
    "\n",
    "\n",
    "- Gradient Descent의 대칭(symmetric)을 피하기 위해 모든 hidden layer에 대해 연결 가중치를 임의로 초기화하는 것이 중요함.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### - b = tf.Variable(tf.zeros([n_neurons]), name='bias')\n",
    "\n",
    "- 0으로 초기화 된 bias에 대한 변수b 를 만든다. \n",
    "\n",
    "- 뉴런 당 하나의 bias 파라미터가 있다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### - Z = tf.matmul(X, W) + b\n",
    "\n",
    " - Z = X · W + b를 계산하기 위한 부분 그래프(subgraph)를 만든다. \n",
    " - 이 벡터화 된 구현은 한번에 batch 내 모든 인스턴스에 대해 입력의 가중치 합계와 (weighted sums of the inputs) 레이어 내 각 뉴런에 대한 bias term을 효율적으로 계산한다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### - if activation is not None: ~ return Z\n",
    "\n",
    "- 마지막으로 tf.nn.relu (즉, max(0,Z))와 같은 활성화 파라미터가 제공되면, 코드는 활성화(activation) (Z)를 반환하거나 그렇지 않으면 Z만 반환한다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -  생성한 neuron_layer함수를 통해 DNN을 만들어보자 \n",
    "- 첫번째 은닉레이어는 X를 입력으로 사용함 \n",
    "- 두번째 은닉레이어는 첫번째 은닉레이어의 출력을 입력으로 사용함 \n",
    "- 출력레이어는 두번째 은닉레이어의 출력을 입력으로 사용함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = neuron_layer(X, n_hidden1, name=\"hidden1\",activation=tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, name=\"hidden2\",activation=tf.nn.relu)\n",
    "    logits = neuron_layer(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- logits은 softmax 활성화 함수를 거치기 전의 인공신경망의 출력 (후에 softmax 활성화 적용) \n",
    "\n",
    "#### - 직접 만든 함수 대신 기존의 함수 가져다 사용하기 \n",
    "- 텐서플로우의 fully_connected()함수는 모든 입력이 모든 레이어의 뉴런과 연결되는 fully connected layer를 생성함 \n",
    "    - 적절한 초기화 전략으로 가중치와 바이어스 값을 생성함 \n",
    "    - 기본값으로 ReLU 활성화 함수를 사용함 (activatoin_fn을 통해 변경 가능)\n",
    "    - 파라미터의 제약과 정규화도 지원 (11장에서 설명) \n",
    "\n",
    "\n",
    "- 위의 코드에 fully_connected()를 사용해보자 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import fully_connected\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = fully_connected(X, n_hidden1, scope=\"hidden1\") #기본활성화함수가 relu\n",
    "    hidden2 = fully_connected(hidden1, n_hidden2, scope=\"hidden2\")\n",
    "    logits = fully_connected(hidden2, n_outputs, scope=\"outputs\", activation_fn=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  - 학습에 사용할 비용함수를 정의\n",
    "- 4장의 softmax regression에서 사용한 교차 엔트로피(cross entropy)사용 \n",
    "    - 교차 엔트로피는 타겟 클래스에 대해 낮은 확률을 추정하는 모델에게 패널티를 줌 \n",
    " \n",
    " \n",
    "- 텐서플로우에서 교차 엔트로피를 계산하는 몇 가지 함수를 제공함  \n",
    "- sparse_softmax_cross_entropy_with_logits()함수는 'logits'을 기준으로 교차 엔트로피 계산 \n",
    "    - logits은 softmax활성화 함수가 적용되기 전의 네트워크 출력 \n",
    "\n",
    "\n",
    "- 0 ~ (클래스개수 - 1)의 범위를 가지는 정수 형태의 label을 예측함 (0~9)\n",
    "- 각 데이터에 대해 교차 엔트로피를 가지는 1차원 텐서를 반환함 \n",
    "- 각각의 교차 엔트로피 계산 후 텐서플로우의 reduce_mean() 함수를 사용하여 모든 데이터에 대한 평균 교차 엔트로피를 계산 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?,)\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=y, logits=logits) #y는 타겟값, logits은 예측값\n",
    "    \n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    print(xentropy.shape)\n",
    "    print(loss.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "x = [0]\n",
    "y = [[1], [0]]\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=x, logits=y) #y는 타겟값, logits은 예측값\n",
    "print(xentropy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - GradientDescentOptimizer 정의 하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss) #loss를 최소화 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 모델을 어떻게 평가할 것인지 정하기 \n",
    "- 간단하게 정확도(accuracy)를 성능 척도로 사용 \n",
    "- 먼저, 각 데이터에 대해 가장 높은 logit이 타겟 클래스에 해당되는지 여부를 확인하여 신경망의 예측이 올바른지 확인 \n",
    "    - in_top_k() 함수를 사용 (불리언 값의 1차원 텐서를 반환) \n",
    "    - 불리언 값을 float형으로 casting한 후 평균을 계산 (네크워크 전체의 정확도를 얻을 수 있음) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1) #상위 첫번째 logits(예측)과 y(타겟)가 일치하는가 \n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 변수 초기화 노드 생성\n",
    "- 학습 된 모델 파라미터 변수를 디스크에 저장하는 Saver 노드 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 결론적으로 \n",
    "- input과 target에 대한 placeholder 생성 \n",
    "- DNN 생성에 사용하는 neuron layer 함수 정의\n",
    "- 비용함수(cost function) 정의\n",
    "- 최적화 도구(optimizer) 생성 \n",
    "- 성능 측정(Performance measure) 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution Phase \n",
    "#### - MNIST 데이터를 불러옴 \n",
    "- Scikit-learn 대신 텐서플로우에서 데이터를 불러옴 \n",
    "    - 데이터를 가져와 0에서 1사이로 스케일링하고, 데이터를 섞고, mini-batch를 로드하는 간단한 함수를 제공하는 자체 helper가 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('/tmp/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.9 Val accuracy: 0.9092\n",
      "1 Train accuracy: 0.98 Val accuracy: 0.9308\n",
      "2 Train accuracy: 0.96 Val accuracy: 0.939\n",
      "3 Train accuracy: 0.94 Val accuracy: 0.9478\n",
      "4 Train accuracy: 0.98 Val accuracy: 0.951\n",
      "5 Train accuracy: 0.94 Val accuracy: 0.9578\n",
      "6 Train accuracy: 0.94 Val accuracy: 0.9598\n",
      "7 Train accuracy: 1.0 Val accuracy: 0.9628\n",
      "8 Train accuracy: 0.96 Val accuracy: 0.9634\n",
      "9 Train accuracy: 1.0 Val accuracy: 0.9658\n",
      "10 Train accuracy: 1.0 Val accuracy: 0.9662\n",
      "11 Train accuracy: 1.0 Val accuracy: 0.9656\n",
      "12 Train accuracy: 1.0 Val accuracy: 0.9672\n",
      "13 Train accuracy: 1.0 Val accuracy: 0.9676\n",
      "14 Train accuracy: 0.96 Val accuracy: 0.9706\n",
      "15 Train accuracy: 1.0 Val accuracy: 0.9696\n",
      "16 Train accuracy: 0.98 Val accuracy: 0.97\n",
      "17 Train accuracy: 1.0 Val accuracy: 0.9714\n",
      "18 Train accuracy: 1.0 Val accuracy: 0.9718\n",
      "19 Train accuracy: 1.0 Val accuracy: 0.9736\n",
      "20 Train accuracy: 1.0 Val accuracy: 0.9736\n",
      "21 Train accuracy: 1.0 Val accuracy: 0.9748\n",
      "22 Train accuracy: 0.98 Val accuracy: 0.9746\n",
      "23 Train accuracy: 0.98 Val accuracy: 0.9748\n",
      "24 Train accuracy: 1.0 Val accuracy: 0.977\n",
      "25 Train accuracy: 0.96 Val accuracy: 0.9744\n",
      "26 Train accuracy: 0.98 Val accuracy: 0.9772\n",
      "27 Train accuracy: 0.98 Val accuracy: 0.9762\n",
      "28 Train accuracy: 1.0 Val accuracy: 0.9768\n",
      "29 Train accuracy: 0.98 Val accuracy: 0.9762\n",
      "30 Train accuracy: 0.98 Val accuracy: 0.9772\n",
      "31 Train accuracy: 1.0 Val accuracy: 0.9782\n",
      "32 Train accuracy: 0.94 Val accuracy: 0.9772\n",
      "33 Train accuracy: 1.0 Val accuracy: 0.979\n",
      "34 Train accuracy: 1.0 Val accuracy: 0.979\n",
      "35 Train accuracy: 1.0 Val accuracy: 0.9784\n",
      "36 Train accuracy: 1.0 Val accuracy: 0.9784\n",
      "37 Train accuracy: 1.0 Val accuracy: 0.9782\n",
      "38 Train accuracy: 0.98 Val accuracy: 0.9782\n",
      "39 Train accuracy: 1.0 Val accuracy: 0.979\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 50\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run() #변수 초기화 \n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size): #mini-batch의 수 만큼 반복 \n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size) \n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict={X: mnist.validation.images,\n",
    "                                            y: mnist.validation.labels})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Val accuracy:\", acc_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Neural Network \n",
    "#### - 학습된 신경망을 통해 예측을 수행 \n",
    "- 동일한 construction phase를 재사용하며 execution phase만 조금 변경 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "Predicted classes: [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]\n",
      "Actual classes:    [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\") #디스크에서 모델 파라미터 변수를 불러옴 \n",
    "    X_new_scaled = mnist.test.images[:20] #새로운 데이터 (학습데이터와 동일한 feature scaling 필요)\n",
    "    Z = logits.eval(feed_dict={X: X_new_scaled})\n",
    "    y_pred = np.argmax(Z, axis=1) #클래스 예측만을 위해서는 argmax() 사용 \n",
    "\n",
    "print(\"Predicted classes:\", y_pred)  #예측\n",
    "print(\"Actual classes:   \", mnist.test.labels[:20])  #타겟 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAADm5JREFUeJzt3XGQlPV9x/HP947zCAQRSjwJoBhD\nI9YpmJwYQ6alk8HRlAbtVCIzMTiT6aVtjLVjM7G0M3Ha6QzTaUxMm5peAhMyUZKMSiQTWmNpM5gx\nEg6bUfQErUEhUE6KCpjk4I5v/7gH54L3/HbZfXafPb7v1wxzu8/3+e3zndXPPbv3e3Z/5u4CEE9b\n2Q0AKAfhB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8Q1IRmHuwc6/SJmtzMQwKh/Epv6LgPWjX7\n1hV+M7tW0j2S2iV9zd3XpPafqMm6yj5UzyEBJGzzLVXvW/PLfjNrl/RlSddJukzSSjO7rNbHA9Bc\n9bznXyTpBXd/0d2PS/qWpOXFtAWg0eoJ/yxJe0fd35dt+zVm1mNmfWbWd0KDdRwOQJHqCf9Yf1R4\ny+eD3b3X3bvdvbtDnXUcDkCR6gn/PklzRt2fLWl/fe0AaJZ6wr9d0jwzu9jMzpF0k6RNxbQFoNFq\nnupz9yEzu1XSIxqZ6lvn7s8U1hmAhqprnt/dN0vaXFAvAJqIy3uBoAg/EBThB4Ii/EBQhB8IivAD\nQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCKqp\nS3QDo024oCtZPz7vnQ07dsfunyfru/7qXcn6ec+mV8Ge3v+rZL3tsf9O1puBMz8QFOEHgiL8QFCE\nHwiK8ANBEX4gKMIPBFXXPL+Z7ZF0VNKwpCF37y6iKYwfr3/s/cn6/304f777ziv+PTn24+c2bgHo\nta9fmKz/4ZSNyfq0GyfWdfxls95X1/giFHGRz++5+6ECHgdAE/GyHwiq3vC7pB+Y2Q4z6ymiIQDN\nUe/L/sXuvt/Mzpf0qJk95+5bR++Q/VLokaSJmlTn4QAUpa4zv7vvz34OSNooadEY+/S6e7e7d3eo\ns57DAShQzeE3s8lmNuXUbUnXSNpZVGMAGquel/1dkjaa2anHud/d03M3AFpGzeF39xclLSiwFzRA\n24L5yfpzn56crD92zReT9Xe0b08fv0UnlD4x9eUKe9Q3jz8etOZ/GQANR/iBoAg/EBThB4Ii/EBQ\nhB8Iiq/uPsu9cfGUZH33dfdWeIS3FddMk33ltfyv377vpSub2MlbTdULpR5f4swPhEX4gaAIPxAU\n4QeCIvxAUIQfCIrwA0Exz98EE2bPStb7Pzs7We96PL0c9LkbnsittQ16cuzuE8eT9b1D5yXrcya8\nlqzfsnNVbu3V/t9Iju3anu79vMf3Jut+7Fhubepr5c+zl40zPxAU4QeCIvxAUIQfCIrwA0ERfiAo\nwg8ExTx/AdrPm5qsL/r+z5L1787YlKwv7rv1jHs6pfPf0l+t/ZnfvyVZH35mV7LePn9esj591//k\n107uTo6tZKiu0eDMDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBVZznN7N1kpZJGnD3y7Nt0yV9W9Jc\nSXskrXD3VxvXZvnaJuYv2Tz4QHqef/WM/0zW3/PQnyXrl258JlkfTlbTKs3jVxzf/3xd41Geas78\nX5d07Wnb7pS0xd3nSdqS3QcwjlQMv7tvlXT4tM3LJa3Pbq+XdH3BfQFosFrf83e5+wFJyn6eX1xL\nAJqh4df2m1mPpB5JmqhJjT4cgCrVeuY/aGYzJSn7OZC3o7v3unu3u3d3qLPGwwEoWq3h3yTp1Ney\nrpL0cDHtAGiWiuE3sw2SfizpPWa2z8w+IWmNpKVm9rykpdl9AONIxff87r4yp/ShgnspVfu0acn6\nc3/3m7m1XfP/JTl2x2D62Jf+7YvJ+vCRI+kHAGrAFX5AUIQfCIrwA0ERfiAowg8ERfiBoPjq7sz+\nj81P1nfd8E+5tU1vpKcJ1y5bmqwPv5L/9dZAo3DmB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgmOfP\nHL3qlzWPvedn6U83v2038/hoPZz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAo5vkzGxb3Vtgj//fk\nA5d9Mzny6rvvSNYv3nQ8WW//4ZPJOlALzvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EFTFeX4zWydp\nmaQBd78823aXpD+W9Eq222p339yoJpthUWdHsn7Ch3Nr09omJsc+99Evpx97Rf5jS9LlW/4kWZ+6\nPf/4x2Z7cuy56dXBNeOpN9I7VHDotyfn1rp+OJAcO8z3IDRUNWf+r0u6doztX3D3hdm/cR18IKKK\n4Xf3rZION6EXAE1Uz3v+W83sKTNbZ2bp9aoAtJxaw3+vpEskLZR0QNLn83Y0sx4z6zOzvhMarPFw\nAIpWU/jd/aC7D7v7SUlflbQosW+vu3e7e3eHOmvtE0DBagq/mc0cdfcGSTuLaQdAs1Qz1bdB0hJJ\nM8xsn6TPSVpiZgsluaQ9kj7ZwB4BNIC5p+eBi3SuTferLP0d92XZ/a9XpuvLvtKkTuL4yaAl67c/\ne1OyPn3Z7iLbOSts8y064ofTT2yGK/yAoAg/EBThB4Ii/EBQhB8IivADQTHVl7EJ6Useji9ZkFv7\n+D9/Lzl2Ulv6suZlk15J1jusPVk/W53UyWT9t+6/LVm/5DM/LrKdcYGpPgAVEX4gKMIPBEX4gaAI\nPxAU4QeCIvxAUCzRnfGhoWS94z925NY2XPrOuo79pT9Kf3R1uCM9bfuBv/xJbm3NBdtr6qkVtFU4\nN81ecKBJnZydOPMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFDM87eAyQ9sq2v89xZcnVtbc3N6nv8X\nfjxZf9/WP03WL/pa+rsGDt32i9xa35XfTI5FY3HmB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgKs7z\nm9kcSd+QdIGkk5J63f0eM5su6duS5kraI2mFu7/auFaR58JHEusC3JweO8nOSdb7f3dtsn7zRUuT\n9c1zH0lU6zv3vPy/05P1edpT1+Of7ap59ock3eHu8yW9X9KnzOwySXdK2uLu8yRtye4DGCcqht/d\nD7j7k9nto5L6Jc2StFzS+my39ZKub1STAIp3Rq+7zGyupCskbZPU5e4HpJFfEJLOL7o5AI1TdfjN\n7O2SHpR0u7sfOYNxPWbWZ2Z9J5Resw5A81QVfjPr0Ejw73P3h7LNB81sZlafKWlgrLHu3uvu3e7e\n3aHOInoGUICK4Tczk7RWUr+73z2qtEnSquz2KkkPF98egEapuES3mX1Q0mOSnpbeXDN5tUbe939H\n0oWSXpZ0o7sfTj1WKy/RPZ61TZmSWxu4f2Zy7BPv3VB0O1Ub9BPJ+rJn019pPmlFemZ5+LXXz7in\n8e5MluiuOM/v7j+SlPdgJBkYp7jCDwiK8ANBEX4gKMIPBEX4gaAIPxAUX919Fjh59Ghu7YJPT0uO\n/YN1H0nWV8/9frJ+dedwsv7gsRm5tb/e/NHk2Hf/xRPJevrIqIQzPxAU4QeCIvxAUIQfCIrwA0ER\nfiAowg8EVfHz/EXi8/zjz8HbPpCsH73yl8n6pX9zKLc29NLemnpCvjP5PD9nfiAowg8ERfiBoAg/\nEBThB4Ii/EBQhB8Iis/zI6nrS4+n6xXGDxXXCgrGmR8IivADQRF+ICjCDwRF+IGgCD8QFOEHgqoY\nfjObY2b/ZWb9ZvaMmf15tv0uM/u5mf00+/fhxrcLoCjVXOQzJOkOd3/SzKZI2mFmj2a1L7j7Pzau\nPQCNUjH87n5A0oHs9lEz65c0q9GNAWisM3rPb2ZzJV0haVu26VYze8rM1pnZmOtCmVmPmfWZWd8J\nDdbVLIDiVB1+M3u7pAcl3e7uRyTdK+kSSQs18srg82ONc/ded+929+4OdRbQMoAiVBV+M+vQSPDv\nc/eHJMndD7r7sLuflPRVSYsa1yaAolXz136TtFZSv7vfPWr7zFG73SBpZ/HtAWiUav7av1jSzZKe\nNrOfZttWS1ppZgsluaQ9kj7ZkA4BNEQ1f+3/kaSxvgd8c/HtAGgWrvADgiL8QFCEHwiK8ANBEX4g\nKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8EZe7evIOZvSLppVGbZkg61LQGzkyr9taq\nfUn0Vqsie7vI3d9RzY5NDf9bDm7W5+7dpTWQ0Kq9tWpfEr3VqqzeeNkPBEX4gaDKDn9vycdPadXe\nWrUvid5qVUpvpb7nB1Cess/8AEpSSvjN7Foz22VmL5jZnWX0kMfM9pjZ09nKw30l97LOzAbMbOeo\nbdPN7FEzez77OeYyaSX11hIrNydWli71uWu1Fa+b/rLfzNol7Za0VNI+SdslrXT3Z5vaSA4z2yOp\n291LnxM2s9+RdEzSN9z98mzbP0g67O5rsl+c09z9sy3S212SjpW9cnO2oMzM0StLS7pe0i0q8blL\n9LVCJTxvZZz5F0l6wd1fdPfjkr4laXkJfbQ8d98q6fBpm5dLWp/dXq+R/3maLqe3luDuB9z9yez2\nUUmnVpYu9blL9FWKMsI/S9LeUff3qbWW/HZJPzCzHWbWU3YzY+jKlk0/tXz6+SX3c7qKKzc302kr\nS7fMc1fLitdFKyP8Y63+00pTDovd/b2SrpP0qezlLapT1crNzTLGytItodYVr4tWRvj3SZoz6v5s\nSftL6GNM7r4/+zkgaaNab/Xhg6cWSc1+DpTcz5taaeXmsVaWVgs8d6204nUZ4d8uaZ6ZXWxm50i6\nSdKmEvp4CzObnP0hRmY2WdI1ar3VhzdJWpXdXiXp4RJ7+TWtsnJz3srSKvm5a7UVr0u5yCebyvii\npHZJ69z975vexBjM7F0aOdtLI4uY3l9mb2a2QdISjXzq66Ckz0n6rqTvSLpQ0suSbnT3pv/hLae3\nJRp56frmys2n3mM3ubcPSnpM0tOSTmabV2vk/XVpz12ir5Uq4XnjCj8gKK7wA4Ii/EBQhB8IivAD\nQRF+ICjCDwRF+IGgCD8Q1P8Df2wQFZ1eHhYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x191e4d80358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "img2=plt.imshow(X_new_scaled[8,:].reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning Neural Network Hyperparameters\n",
    "#### - 신경망에는 조정해야 할 많은 파라미터가 존재하기 떄문에 유연성의 단점을 가짐 \n",
    "#### - 최적의 파라미터 조합을 찾는 방법 \n",
    "- 교차검증과 함께 grid search를 사용 \n",
    "    - tuning할 파라미터가 많고, 대규모 데이터 셋에서의 신경망 학습에 너무 오랜 시간이 걸림 \n",
    "    - randomized search(2장)를 사용하는 것이 좋음 \n",
    "\n",
    "\n",
    "- Oscar와 같은 도구를 사용 \n",
    "    - 더 복잡한 알고리즘을 구현하여 좋은 파라미터 집합을 빠르게 찾을 수 있도록 해줌 \n",
    "    \n",
    "  \n",
    "- 각 파라미터에 대해 합리적인 값이 무엇인지 생각하는 것은 검색 공간을 제한할 수 있음 \n",
    "\n",
    "\n",
    "### Number of Hidden Layers \n",
    "#### - 1개의 은닉레이어만으로도 합리적인 결과를 얻을 수 있음 \n",
    "#### - 하지만 깊은 신경망은 얕은 신경망보다 더 높은 파라미터 효율성(parameter efficiency)를 가짐 \n",
    "- 얕은 신경망보다 훨씬 적은 뉴런을 사용하기 때문에 학습속도가 더 빠름 \n",
    "\n",
    "\n",
    "#### - 새로운 데이터 셋을 일반화하는 능력을 향상시킴 \n",
    "- 이미 학습한 네트워크의 하위 레이어를 재사용하여 사용할 수 있음 \n",
    "\n",
    "\n",
    "#### - 두 개의 은닉레이어로도 충분할 수 있음 \n",
    "- 더 복잡한 문제의 경우 학습 셋의 overfitting이 시작될 때까지 은닉레이어의 수를 점차적으로 늘릴 수 있음 \n",
    "\n",
    "\n",
    "#### - 여러 경우의 네트워크가 존재함 \n",
    "- 매우 복잡한 작업에 일반적으로 필요한 수십개의 레이어를 가진 네트워크 \n",
    "- 수백개의 레이어가 있지만 완전히 연결(fully_connected)되지 않은 네트워크 \n",
    "\n",
    "\n",
    "#### - 하지만 대부분의 경우 이러한 네트워크를 처음부터 학습할 필요는 없음 \n",
    "- 비슷한 작업을 수행하는 미리 학습된 네트워크의 일부를 재사용하는 것이 일반적 \n",
    "- 학습은 빨라지며, 적은 데이터를 필요로 함 (11장에서 설명)\n",
    "\n",
    "\n",
    "### Number of Neurons per Hidden Layer \n",
    "#### - 입력레이어와 출력레이어의 뉴런 개수는 작업에 필요한 입력과 출력의 유형에 따라 결정됨 \n",
    "- MNIST 작업에는 784개(28*28)의 입력 뉴런과 10개(0 ~ 9)의 출력 뉴런이 필요함 \n",
    "\n",
    "\n",
    "#### - 은닉레이어에서 뉴런의 개수 또한 네트워크의 overfitting이 시작될 때 까지 점차적으로 늘릴 수 있음 \n",
    "#### - 일반적으로 레이어 당 뉴런의 개수보다 레이어의 수를 증가시키는 것이 더 나음 \n",
    "#### - 불행하게도, 알다시피 뉴런의 완벽한 개수를 찾는 것은 거의 불가능 함 \n",
    "#### - 더 간단한 접근법은 \n",
    "- 실제로 필요한 것 보다 더 많은 레이어와 뉴런을 가진 모델을 선택한 후 \n",
    "- early stopping을 사용하여 overfitting을 방지하는 방법이 있음 \n",
    "- stretch pants \n",
    "\n",
    "\n",
    "### Activation Functions \n",
    "#### - 대부분의 경우 은닉레이어에서 ReLU 활성화 함수를 사용할 수 있음 \n",
    "- 혹은 ReLU의 변형(11장에서 설명) \n",
    "- 다른 활성화 함수보다 계산이 빠름 \n",
    "- Gradient Descent도 잘 작동함 \n",
    "\n",
    "#### - 출력레이어의 경우, 분류 작업에서는 sotfmax 활성화 함수가 적합함 (클래스들이 상호 배타적인 경우) \n",
    "#### - 출력레이어의 경우, 회귀 작업에서는 활성화 함수를 전혀 사용하지 않을 수 있음 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
