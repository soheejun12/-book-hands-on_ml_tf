{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 15. Autoencoders\n",
    "\n",
    "## * Autoencoder \n",
    "### : 비지도학습(라벨화된 학습데이터 사용 x)에서 입력 데이터의 효율적인 재형성(coding)이 가능한 인공신경망\n",
    "\n",
    "### - 보통 conding은 입력데이터보다 더 낮은 차원을 가지기 때문에 autoencoder는 차원축소에 유용하게 사용됨\n",
    "### - autoencoder의 기능 \n",
    "- 강력한 특징 탐지기 \n",
    "- Deep Neural Network의 비지도 선행학습 \n",
    "- 학습 데이터와 비슷한 새로운 데이터 생성 (generative model)\n",
    "\n",
    "\n",
    "\n",
    "### - autoencoder는 간단하게 입력을 출력으로 복사하는 것을 학습하여 작동함 \n",
    "- 간단해보이지만 네트워크를 다양한 방법으로 제약(constraining)하여 autoencoder가 바로 입력을 출력으로 복사하지 않게 함 \n",
    "    - 내부 재형성의 크기를 줄임\n",
    "    - 입력에 노이즈를 주고 원본을 출력하도록 학습 \n",
    "\n",
    "\n",
    "### - coding은 제약 속에서 autoencoder가 항등함수를 학습할 때 생기는 부산물이다  \n",
    "\n",
    "#### 이번장에서는 \n",
    "- autoencoder의 작동원리 \n",
    "- 적용할 수 있는 제약의 종류 \n",
    "- Tensorflow를 통해 autoencoder 구현 \n",
    "    - 차원 축소 \n",
    "    - 특징 추출 \n",
    "    - 비지도 선행학습 \n",
    "    - 생성 모델 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficient Data Representations \n",
    "\n",
    "- 긴 데이터라도 특징이 있다면 기억하기 쉬워지며, 다시 작성도 쉬워진다 \n",
    "- 긴 연속숫자들을 암기하기 어렵다는 사실은 그 데이터의 패턴을 인식하기 유용하게 만든다 \n",
    "    - 이것은 autoencoder의 학습 동안 데이터의 패턴을 발견하고 활용하도록 제약을 두는 이유이다 \n",
    "    \n",
    "    \n",
    "- 전문가들이 밝혀내기를, 체스전문플레이어들은 일반인들과 달리 보드를 5초만 봐도 게임의 모든 부분의 위치를 기억할 수 있다 \n",
    "    - 이것은 부분들이 각각 임의가 아닌 서로 연관된 위치에 놓여있기 때문 \n",
    "    - 일반인보다 기억력이 좋은것이 아니라 일반인보다 많은 체스 경험이 패턴을 파악하기에 쉬웠던 것 \n",
    "    - 패턴을 알아차리는 것은 정보를 효율적으로 저장하도록 도움 \n",
    "    \n",
    "\n",
    "- 예시와 같이 autoencoder는 입력을 파악하고 그것을 효율적인 내부 재형성으로 변환하고 그것을 입력과 매우 비슷한 출력으로 나타내는 것 \n",
    "\n",
    "### - autoencoder는 항상 두 부분으로 구성 \n",
    "#### - encoder (인식 네트워크)\n",
    "- 입력을 내부 재형성으로 변환 \n",
    "\n",
    "\n",
    "#### - decoder (생성 네트워크)\n",
    "- 내부 재형성을 출력으로 변환 \n",
    "\n",
    "### - autoencoder는 다층퍼셉트론과 같은 구조를 가짐 \n",
    "####  하지만 반드시 입력층의 뉴런 개수와 출력층의 뉴런 개수가 같아야 함 \n",
    "<img src = \"image\\ch15\\chess.png\">\n",
    "- 한개의 은닉층은 2개의 뉴런(encoder)으로 구성  \n",
    "- 출력층은 3개의 뉴런(decoder)으로 구성\n",
    "\n",
    "\n",
    "#### - 출력은 autoencdoer가 입력을 재형성하려 시도할 때 종종 복원(reconstructions)이라 불림 \n",
    "#### - 비용함수는 복원이 입려과 다를 때 모델에 벌을 주기 위한 복원 손실을 포함함 \n",
    "\n",
    "### - Undercomplete\n",
    "-  : 내부 재형성이 입력 데이터보다 낮은 차원을 가짐 \n",
    "- undercomplete autoencoder는 입력을 coding에 바로 그대로 복사하지 못하기 때문에 입력을 출력에 어떻게 복사할 것인지 찾아야 함\n",
    "    - 입력 데이터의 중요하지 않은 특징들은 버리고 가장 중요한 특징들만을 학습할 수 밖에 없음 \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing PCA with and Undercomplete Linear Autoencoder\n",
    "\n",
    "- 만약 autoencoder가 선형활성화 함수만 사용하고 비용함수로 MSE를 사용한다면 결국 PCA를 수행해 끝날 것을 보여줌 \n",
    "\n",
    "#### - 3차원 데이터를 2차원에 영사시키는 PCA를 수행하는 간단한 선형 autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "\n",
    "n_inputs = 3 #3차원 입력 \n",
    "n_hidden = 2 #2차원으로 encoding\n",
    "n_outputs = n_inputs #출력층의 노드 개수는 입력층의 노드 개수와 동일해야함 \n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "#그래프 만들기 \n",
    "X = tf.placeholder(tf.float32, shape=[None, n_inputs])\n",
    "hidden = fully_connected(X, n_hidden, activation_fn=None) #입력층-은닉층\n",
    "outputs = fully_connected(hidden, n_outputs, activation_fn=None) #은닉층-출력층 \n",
    "\n",
    "reconstruction_loss = tf.reduce_mean(tf.square(outputs - X)) #비용함수 MSE\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(reconstruction_loss) #reconstruction_loss를 최소화시키도록 학습 \n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MLP와 매우 비슷한 구조지만 조금 다름 \n",
    "    - 출력의 개수는 입력의 개수와 같음 \n",
    "    - 간단한 PCA를 수행하기 위해서, activation_fn=None으로, 비용함수를 MSE로 설정 \n",
    "    \n",
    "#### - 데이터를 불러와 학습셋에 대해 모델을 학습하고 테스트셋 재형성에 사용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "\n",
    "#데이터 만들기 \n",
    "rnd.seed(4)\n",
    "m = 200\n",
    "w1, w2 = 0.1, 0.3\n",
    "noise = 0.1\n",
    "\n",
    "angles = rnd.rand(m) * 3 * np.pi / 2 - 0.5\n",
    "data = np.empty((m, 3))\n",
    "data[:, 0] = np.cos(angles) + np.sin(angles)/2 + noise * rnd.randn(m) / 2\n",
    "data[:, 1] = np.sin(angles) * 0.7 + noise * rnd.randn(m) / 2\n",
    "data[:, 2] = data[:, 0] * w1 + data[:, 1] * w2 + noise * rnd.randn(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.02592185e+00,  -6.03764035e-01,  -3.61779903e-01],\n",
       "       [ -4.78796397e-03,   6.76237786e-01,   3.36012274e-01],\n",
       "       [ -1.06729408e+00,  -5.66900983e-01,  -3.30641113e-01],\n",
       "       [ -8.62849091e-01,   1.34195014e-01,   3.32310710e-02],\n",
       "       [ -7.70945331e-01,   2.48766682e-01,  -1.02861880e-01],\n",
       "       [  1.06412364e+00,   4.26245815e-01,   3.00885052e-01],\n",
       "       [ -9.65619888e-01,  -6.03557812e-01,  -2.66196063e-01],\n",
       "       [  5.88804093e-01,  -3.65103013e-01,   1.09935587e-01],\n",
       "       [  1.09173117e+00,   4.34543182e-01,   3.17925292e-01],\n",
       "       [  4.49754726e-01,   7.79687003e-01,   1.93815940e-01],\n",
       "       [ -1.02235571e+00,  -5.44024678e-02,  -8.34171502e-02],\n",
       "       [  1.14286245e+00,   3.19490139e-01,   1.46882802e-01],\n",
       "       [ -1.00702813e+00,  -2.38331713e-01,  -1.50191559e-01],\n",
       "       [ -9.11372244e-01,  -5.55093729e-01,  -1.01202740e-01],\n",
       "       [  1.17844560e+00,   1.71149025e-01,   3.28981558e-01],\n",
       "       [ -3.06034060e-01,   5.47607256e-01,   1.54151621e-01],\n",
       "       [  7.81955940e-01,  -3.00848690e-01,  -8.85170381e-02],\n",
       "       [  7.19054923e-01,   7.19001380e-01,   2.99503776e-01],\n",
       "       [  8.01202293e-01,  -1.81813051e-01,   2.36327157e-01],\n",
       "       [ -1.09262319e+00,  -5.26267803e-01,  -2.75770660e-01],\n",
       "       [  5.26555551e-01,   6.13404740e-01,   9.65672622e-02],\n",
       "       [ -9.91018162e-01,  -4.84450051e-01,  -3.77551091e-01],\n",
       "       [ -1.06153109e+00,  -5.02957393e-02,  -2.35319148e-01],\n",
       "       [ -1.13626972e+00,  -4.02171392e-01,  -1.22749867e-01],\n",
       "       [  1.08269615e+00,   2.15426041e-01,   1.43277864e-01],\n",
       "       [  8.99526538e-01,  -8.75851390e-02,  -6.04312730e-03],\n",
       "       [ -3.56169157e-01,   5.01416676e-01,   1.53922146e-01],\n",
       "       [  1.03401614e+00,   7.93707312e-02,   2.27147047e-01],\n",
       "       [ -8.21495626e-01,   9.30350921e-02,  -6.51689732e-02],\n",
       "       [  5.41620482e-01,   6.44466855e-01,   1.71863483e-01],\n",
       "       [  5.87507813e-03,   6.24224673e-01,   2.12834236e-01],\n",
       "       [ -1.04653941e+00,  -6.05251097e-01,  -2.01266215e-01],\n",
       "       [  1.35476792e-01,   6.62173278e-01,   5.18583565e-02],\n",
       "       [  9.94446028e-01,   3.35727669e-02,  -2.58188674e-02],\n",
       "       [  1.07740096e+00,   1.98934436e-01,   3.69055086e-01],\n",
       "       [ -3.63845967e-02,   6.12191298e-01,   2.26638957e-01],\n",
       "       [  5.76005943e-02,   6.39744218e-01,   2.37244098e-01],\n",
       "       [ -4.62727961e-01,   4.66615916e-01,  -4.09865172e-02],\n",
       "       [  6.45728099e-01,   7.11557411e-01,   1.83929890e-01],\n",
       "       [ -6.12245021e-01,   3.62575785e-01,   2.50663945e-02],\n",
       "       [  6.65464970e-01,   7.01014073e-01,   4.04603026e-01],\n",
       "       [ -4.36423423e-01,   4.86486722e-01,   1.14872129e-01],\n",
       "       [ -9.25580134e-01,   7.77209149e-02,  -2.26805104e-01],\n",
       "       [  1.18995379e+00,   2.59262903e-01,   3.52940716e-01],\n",
       "       [  7.53974269e-01,   6.29720710e-01,   4.25026849e-01],\n",
       "       [  1.11878045e-01,   6.45162311e-01,   2.94750181e-01],\n",
       "       [ -7.90645717e-01,   2.87565177e-01,  -9.87788222e-02],\n",
       "       [  1.19440035e+00,   4.64089689e-01,   1.97662261e-01],\n",
       "       [ -1.09168521e-01,   6.50235914e-01,   1.60532863e-01],\n",
       "       [ -4.23248712e-01,   3.55978412e-01,   8.00521837e-02],\n",
       "       [ -1.01482210e+00,  -4.17839441e-01,  -4.56053368e-02],\n",
       "       [  7.86891992e-01,   5.98156278e-01,   1.26848801e-01],\n",
       "       [ -5.16044035e-01,   4.70617672e-01,   2.15452377e-02],\n",
       "       [  1.08689209e+00,   3.12690768e-01,   2.03579819e-01],\n",
       "       [  1.54866377e-01,   6.90735179e-01,   1.68497798e-01],\n",
       "       [  1.15199319e+00,   2.87135651e-01,   1.52836948e-01],\n",
       "       [ -1.03717881e+00,  -4.71182069e-01,  -3.90445236e-01],\n",
       "       [  4.41866276e-01,   7.26236153e-01,   2.67792755e-01],\n",
       "       [ -1.04817496e+00,  -1.83409873e-01,  -1.90786669e-01],\n",
       "       [  5.91935068e-01,   7.01320242e-01,   2.88209971e-01],\n",
       "       [ -1.09494303e+00,  -4.13105507e-01,  -1.40704151e-01],\n",
       "       [  6.65637822e-01,   7.38802448e-01,   2.62723627e-01],\n",
       "       [  8.59331466e-01,   6.64393259e-01,   2.73847753e-01],\n",
       "       [ -1.95538977e-01,   4.97268991e-01,   1.56984513e-01],\n",
       "       [ -1.15938063e+00,  -2.60545895e-01,  -2.37959164e-01],\n",
       "       [ -1.02099407e+00,  -2.78033493e-01,  -1.65071239e-01],\n",
       "       [ -1.91798536e-01,   5.47754865e-01,  -2.72957822e-02],\n",
       "       [  9.48666455e-01,  -1.49873844e-01,  -3.47083225e-02],\n",
       "       [ -3.68039543e-01,   4.69864428e-01,   1.55495678e-01],\n",
       "       [  1.15507300e+00,   4.12561069e-01,   2.59665299e-01],\n",
       "       [ -8.97531981e-01,   2.19060060e-01,   5.78715536e-02],\n",
       "       [ -1.02391772e+00,  -4.22886792e-01,  -3.60732482e-01],\n",
       "       [  2.19857386e-01,   6.37402028e-01,   1.60759179e-01],\n",
       "       [ -2.57188587e-01,   4.99767909e-01,   1.16697282e-01],\n",
       "       [  8.65512126e-01,  -1.39224256e-01,   3.55595140e-02],\n",
       "       [ -6.17527423e-02,   6.30838856e-01,   1.61387504e-01],\n",
       "       [  1.01521895e+00,   7.49500954e-02,   2.64746977e-01],\n",
       "       [ -4.00361453e-01,   4.65895400e-01,   5.42112678e-02],\n",
       "       [  7.71851776e-01,   6.70269031e-01,   2.46546873e-01],\n",
       "       [ -9.28244700e-01,   3.05685453e-02,  -3.31972869e-02],\n",
       "       [  8.62313276e-01,  -1.68466917e-01,   8.24571107e-02],\n",
       "       [  1.00690091e+00,   3.24880258e-02,   1.23575340e-01],\n",
       "       [ -7.30775029e-01,   2.26804801e-01,   1.59362811e-01],\n",
       "       [  1.54307562e-01,   6.65553615e-01,   2.71029205e-01],\n",
       "       [ -1.08487546e-01,   5.76435645e-01,   1.38857650e-01],\n",
       "       [ -1.20518152e+00,  -1.90515508e-01,  -2.73095390e-01],\n",
       "       [  2.73144684e-01,   7.16619619e-01,   3.63433496e-01],\n",
       "       [ -1.08716060e+00,  -4.52654635e-02,  -1.84022418e-01],\n",
       "       [  1.07698927e-01,   6.22359970e-01,   2.35862844e-01],\n",
       "       [ -1.09699239e+00,  -4.70462642e-01,  -3.03031130e-01],\n",
       "       [ -6.32273253e-01,   3.46051624e-01,   2.48956033e-01],\n",
       "       [  1.17312932e+00,   1.08960360e-01,   2.21806925e-01],\n",
       "       [  8.17645239e-01,   6.44075485e-01,   1.00805664e-01],\n",
       "       [ -1.13916248e+00,  -3.14778809e-01,  -1.80181179e-01],\n",
       "       [  8.03027791e-01,   6.16081745e-01,   1.28230989e-01],\n",
       "       [  1.15376567e+00,   3.80104346e-01,   1.73348078e-01],\n",
       "       [  3.00562762e-01,   6.88348073e-01,   3.15807702e-01],\n",
       "       [  7.00368564e-01,   7.56864067e-01,   1.68635308e-01],\n",
       "       [ -3.81324989e-01,   4.22534582e-01,   1.20513062e-01],\n",
       "       [  5.15162277e-01,   7.14654479e-01,   2.57814366e-01],\n",
       "       [  1.05942520e+00,   4.36012543e-01,   3.10413439e-01],\n",
       "       [  6.14058102e-01,   7.11969394e-01,   1.78006067e-01],\n",
       "       [  6.38605171e-01,   7.80253592e-01,   3.58157000e-01],\n",
       "       [ -1.10690486e+00,  -3.04298515e-01,  -2.38643226e-01],\n",
       "       [ -9.63027433e-01,  -5.37936090e-01,  -1.57043228e-01],\n",
       "       [ -4.18412667e-01,   4.76368859e-01,   1.04085314e-01],\n",
       "       [  9.23549159e-01,  -7.39899349e-02,   1.33835406e-01],\n",
       "       [ -8.72930561e-01,   1.50981328e-01,   8.92625029e-02],\n",
       "       [ -7.02664671e-01,   3.69646170e-01,   1.47382616e-01],\n",
       "       [ -1.03614656e+00,  -2.52817134e-01,  -1.84054989e-01],\n",
       "       [  8.98870112e-01,   6.21560873e-01,   3.44474117e-01],\n",
       "       [  7.78473438e-01,  -2.01143513e-01,   1.56816685e-02],\n",
       "       [ -3.92371822e-01,   5.32762322e-01,   1.60807332e-01],\n",
       "       [  1.09405120e+00,  -8.30618276e-04,   2.67760389e-01],\n",
       "       [ -9.77520619e-01,   8.65845689e-02,  -1.58742611e-01],\n",
       "       [ -1.06685543e+00,  -1.26808963e-01,  -2.64026747e-01],\n",
       "       [  6.89101968e-01,   6.40944370e-01,   3.06388228e-01],\n",
       "       [ -1.10730246e+00,  -4.29271987e-01,  -2.97637932e-01],\n",
       "       [  1.10959662e+00,   2.71452696e-01,   3.11821813e-01],\n",
       "       [ -1.02578855e+00,  -5.45062047e-01,  -1.83791784e-01],\n",
       "       [  4.16368970e-01,   6.10367126e-01,   2.84293748e-01],\n",
       "       [ -1.02757972e+00,  -1.27823107e-02,  -1.10861362e-01],\n",
       "       [ -1.01095850e+00,   9.63843650e-02,  -1.20588032e-01],\n",
       "       [ -8.96298866e-01,  -5.82175795e-01,  -3.53976669e-01],\n",
       "       [ -1.02997877e+00,  -6.12334348e-01,  -3.43779394e-01],\n",
       "       [  7.94469731e-01,  -1.86165761e-01,   1.79958546e-02],\n",
       "       [  8.26667649e-01,  -2.19105608e-01,  -8.02360760e-02],\n",
       "       [ -5.20501481e-02,   5.63484086e-01,   2.62226673e-01],\n",
       "       [  6.65621723e-01,  -2.36263032e-01,   5.59232778e-02],\n",
       "       [ -4.58214382e-01,   3.23523429e-01,  -8.09562899e-02],\n",
       "       [  6.60291858e-02,   6.85820756e-01,  -5.71655727e-02],\n",
       "       [ -6.19461682e-01,   3.42837072e-01,   1.47181134e-01],\n",
       "       [  6.29863982e-01,   6.69022543e-01,   1.40922484e-01],\n",
       "       [  1.05739317e+00,   4.14052320e-01,  -5.83667945e-02],\n",
       "       [ -9.70089476e-01,  -4.82558440e-01,  -4.08345643e-01],\n",
       "       [ -8.73384541e-01,   1.32938899e-01,  -2.91981966e-02],\n",
       "       [  6.51163933e-01,  -3.09172305e-01,   1.04303506e-01],\n",
       "       [  1.01515428e+00,  -3.01501246e-02,   1.82389882e-01],\n",
       "       [ -4.34356707e-01,   4.53082255e-01,   2.36564029e-01],\n",
       "       [  1.09662091e+00,   4.44665142e-01,   4.18075852e-01],\n",
       "       [  7.03480405e-01,   6.52929549e-01,   4.50166984e-01],\n",
       "       [ -1.04472103e+00,  -1.10660963e-02,  -2.03246015e-01],\n",
       "       [  8.47308362e-01,   7.35009456e-01,   2.85685840e-01],\n",
       "       [ -9.84269923e-01,  -4.45276021e-01,  -2.94128539e-01],\n",
       "       [ -8.17294284e-01,   1.68365110e-01,  -2.58342031e-02],\n",
       "       [ -6.93596726e-02,   5.73447652e-01,   1.30281922e-01],\n",
       "       [  1.17854084e+00,   2.09857067e-01,   2.07005935e-01],\n",
       "       [  7.05250293e-01,   6.83371776e-01,   4.57058638e-01],\n",
       "       [ -9.11125598e-01,  -5.39599594e-03,  -1.62927383e-01],\n",
       "       [ -9.72317768e-01,  -5.91883692e-01,  -2.01229674e-01],\n",
       "       [  8.92927939e-01,  -1.04915910e-01,  -3.84358834e-02],\n",
       "       [  1.09580562e+00,   1.94000856e-01,   3.96386939e-02],\n",
       "       [ -8.51712565e-01,   1.04166095e-01,   4.66343242e-02],\n",
       "       [ -1.16048858e+00,  -1.42446680e-01,  -1.72356492e-01],\n",
       "       [  9.33127359e-01,  -7.66939196e-02,   7.73765924e-02],\n",
       "       [ -1.10795920e+00,  -1.36125668e-01,  -7.90201691e-03],\n",
       "       [ -9.80348152e-01,   7.62171535e-02,  -2.07033345e-01],\n",
       "       [ -7.81838611e-01,   2.44885162e-01,   2.91839497e-03],\n",
       "       [  1.03320695e+00,   5.68915084e-01,   4.19560508e-01],\n",
       "       [  4.80308200e-01,   7.54349401e-01,   1.72243743e-01],\n",
       "       [  8.39335441e-01,   6.63652558e-01,   3.08954467e-01],\n",
       "       [ -9.94866515e-01,  -2.30365678e-01,  -7.62812508e-02],\n",
       "       [  9.64481121e-01,   6.30370175e-01,   3.78044194e-01],\n",
       "       [  9.87118722e-01,   6.13037095e-01,   3.49836199e-01],\n",
       "       [ -1.07596040e+00,  -4.21653054e-01,  -1.36865452e-01],\n",
       "       [ -1.06480228e+00,  -4.24639075e-01,  -1.85434705e-01],\n",
       "       [ -1.05452516e+00,  -5.84224266e-01,  -2.02178325e-01],\n",
       "       [ -1.07165674e+00,  -1.66805967e-01,  -1.18516542e-01],\n",
       "       [  9.52972626e-01,  -1.46340660e-01,  -3.75091587e-02],\n",
       "       [  9.12523201e-01,  -1.01200157e-01,   7.26560106e-02],\n",
       "       [ -5.06376322e-02,   6.52203751e-01,   1.80168255e-01],\n",
       "       [ -1.09227214e+00,  -3.37108532e-01,  -9.70767501e-02],\n",
       "       [ -1.20857089e+00,  -3.46040354e-01,  -1.73472853e-01],\n",
       "       [ -4.63133732e-01,   4.81283437e-01,   1.50169423e-01],\n",
       "       [ -1.07615033e+00,  -5.00394512e-01,  -2.38117428e-01],\n",
       "       [  1.11335896e+00,   2.27732546e-01,   2.46064839e-01],\n",
       "       [  1.07474026e+00,   4.01042076e-01,   1.74934016e-01],\n",
       "       [  9.03230260e-01,   6.92639508e-01,   3.26857237e-01],\n",
       "       [  1.10560747e+00,   4.30003324e-01,   1.73113472e-01],\n",
       "       [  1.07447153e+00,   5.38960787e-01,   2.35793384e-01],\n",
       "       [  9.52260014e-01,   1.39596728e-01,   2.79023470e-02],\n",
       "       [  7.57985642e-01,   6.87501885e-01,   5.03549037e-01],\n",
       "       [  7.43405651e-01,  -2.39867040e-01,   6.38111750e-02],\n",
       "       [  5.53551892e-02,   6.00129909e-01,   9.26463118e-02],\n",
       "       [ -1.06131791e+00,  -4.28271922e-01,  -2.69979461e-01],\n",
       "       [  4.94311004e-01,   7.25840120e-01,   3.02325460e-01],\n",
       "       [ -3.75296480e-01,   4.77902647e-01,   6.31932364e-02],\n",
       "       [ -3.43183851e-01,   4.51506890e-01,   1.75938801e-01],\n",
       "       [ -1.09065298e+00,  -4.74444115e-01,  -2.06275808e-01],\n",
       "       [ -9.15311830e-01,   1.06333550e-01,   5.51886463e-02],\n",
       "       [ -1.10431131e+00,  -1.72983769e-01,  -4.41117172e-01],\n",
       "       [  9.18857427e-01,   6.36122626e-01,   3.58792108e-01],\n",
       "       [ -1.14405161e+00,  -4.38446014e-01,  -2.21345139e-01],\n",
       "       [  1.11122393e+00,   2.15105664e-01,   2.76365847e-01],\n",
       "       [  6.71542009e-01,   7.33219250e-01,   2.32693401e-01],\n",
       "       [ -9.26215608e-01,   6.74725851e-02,  -1.43857289e-01],\n",
       "       [  8.94485135e-01,   6.85502363e-01,   1.84069942e-01],\n",
       "       [ -1.10048310e+00,  -2.78693155e-01,  -1.45803448e-01],\n",
       "       [ -1.07620963e+00,  -3.48924371e-01,  -1.95010188e-01],\n",
       "       [  1.03236239e+00,   2.73787827e-01,   1.81526110e-02]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 3)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(data[:100]) #100개씩\n",
    "X_test = scaler.transform(data[100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_iterations = 1000\n",
    "codings = hidden #은닉층의 출력이 coding을 제공 \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for iteration in range(n_iterations): #1000번 \n",
    "        training_op.run(feed_dict={X: X_train}) #학습데이터 학습\n",
    "    codings_val = codings.eval(feed_dict={X: X_test})  #테스트데이터 encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codings_val.shape  #속성을 2개로 줄임 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR0AAADbCAYAAABQrEVmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCQohY6IBKXQEZGgFDoiEtT/AfAqgaaFN38IAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1dbbc231400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(4,3))\n",
    "\n",
    "plt.plot(codings_val[:,0], codings_val[:, 1], \"b.\")\n",
    "\n",
    "plt.xlabel(\"$z_1$\", fontsize=18)\n",
    "plt.ylabel(\"$z_2$\", fontsize=18, rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"image\\ch15\\pca.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Stacked Autoencoders\n",
    "#### : 여러개의 은닉층을 가진 autoencoder, deep autoencoder라고도 함 \n",
    "\n",
    "### - autoencoder도 다른 신경망과 같이 여러개의 은닉층을 가질 수 있음 \n",
    "#### - 하지만 autoencoder를 너무 강력하게 만들어서는 안됨 \n",
    "- 분명 autoencoder가 학습데이터를 완벽하게 재형성할 것이지만 과정동안 어떠한 유용한 데이터도 학습하지 못하고 새로운 데이터도 잘 생성하지 못함 \n",
    "\n",
    "\n",
    "### - Stacked autoencoder의 구조는 보통 중앙 은닉층에 관해서 대칭 \n",
    "<img src = \"image\\ch15\\stackedae.png\">\n",
    "- MNIST 데이터 사용\n",
    "- 입력층의 뉴런은 784개 \n",
    "- 다음 은닉층은 300개의 뉴런 \n",
    "- 중앙 은닉층은 150개의 뉴런 \n",
    "- 그 다음 은닉층은 300개의 뉴런 \n",
    "- 출력층의 뉴런은 784개 \n",
    "\n",
    "\n",
    "### Tensorflow Implementation\n",
    "#### - MNIST 데이터에 stacked autoencoder 사용 \n",
    "- He initialization, ELU 활성화함수, L2 제약 사용 \n",
    "- 비지도학습이기 때문에 라벨(y)가 없는 것을 제외하고는 예전에 살펴본 코드와 비슷함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28 #입력 784개\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 150  # codings\n",
    "n_hidden3 = n_hidden1 #똑같이 300개 \n",
    "n_outputs = n_inputs  #똑같이 784개\n",
    "\n",
    "learning_rate = 0.01\n",
    "l2_reg = 0.0001\n",
    "\n",
    "#그래프 만들기 \n",
    "X = tf.placeholder(tf.float32, shape=[None, n_inputs])\n",
    "with tf.contrib.framework.arg_scope([fully_connected], \n",
    "                                   activation_fn=tf.nn.elu, #ELU활성화 함수 \n",
    "                                   weights_initializer=tf.contrib.layers.variance_scaling_initializer(), #He initialization\n",
    "                                   weights_regularizer=tf.contrib.layers.l2_regularizer(l2_reg)): #l2 제약 \n",
    "    hidden1 = fully_connected(X, n_hidden1)\n",
    "    hidden2 = fully_connected(hidden1, n_hidden2)\n",
    "    hidden3 = fully_connected(hidden2, n_hidden3)\n",
    "    outputs = fully_connected(hidden3, n_outputs, activation_fn=None)\n",
    "\n",
    "reconstruction_loss = tf.reduce_mean(tf.square(outputs - X)) #복원 loss : MSE \n",
    "\n",
    "reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "loss = tf.add_n([reconstruction_loss] + reg_losses) #최종 loss는 둘을 더한것 \n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train MSE: 0.0208554\n",
      "1 Train MSE: 0.0113726\n",
      "2 Train MSE: 0.0102246\n",
      "3 Train MSE: 0.00990046\n",
      "4 Train MSE: 0.0103758\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 150\n",
    "\n",
    "#실행 \n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        n_batches = mnist.train.num_examples // batch_size\n",
    "        for iteration in range(n_batches):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch})\n",
    "        loss_train = reconstruction_loss.eval(feed_dict={X: X_batch})   # not shown\n",
    "        print(\"\\r{}\".format(epoch), \"Train MSE:\", loss_train)           # not shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55000"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tying Weights \n",
    "#### - autoencoder가 딱 대칭적일 때, 흔한 기술은 decoder층의 가중치와 encoder층의 가중치를  묶는것이다 \n",
    "- 모델의 가중치 개수가 반이 됨 \n",
    "    - 학습 속도가 빨라짐 \n",
    "    - 오버피팅 위험을 제한함 \n",
    "    \n",
    "    \n",
    "- autoencoder가 입력층을 제외하고 총 N개의 레이어를 가질 때 \n",
    "    - 1번째 레이어는 첫번째 은닉층, 중간(N/2) 레이어는 coding레이어, 마지막(N) 레이어는 출력레이어\n",
    "    - WL :L번째 레이어의 연결 가중치를 의미 \n",
    "     <img src = \"image\\ch15\\tying.png\">\n",
    "    \n",
    "        - 대칭되는 레이어의 가중치는 전치 관계 \n",
    "        - W4 = W1^T\n",
    "        - W3 = W2^T\n",
    "        - W2 = W3^T\n",
    "        - W1 = W4^T\n",
    "        \n",
    "        \n",
    "#### - 하지만 Tensorflow에서 fully_connected()를 사용해서 묶인 가중치를 구현하는 것은 복잡함 \n",
    "- 하나씩 레이어를 정의하는 것이 더 쉬움 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activation = tf.nn.elu #ELU 활성화함수 \n",
    "regularizer = tf.contrib.layers.l2_regularizer(l2_reg) #L2 제약\n",
    "initializer = tf.contrib.layers.variance_scaling_initializer() #He initialization\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_inputs])\n",
    "\n",
    "#2개만 \n",
    "weights1_init = initializer([n_inputs, n_hidden1]) \n",
    "weights2_init = initializer([n_hidden1, n_hidden2])\n",
    "\n",
    "weights1 = tf.Variable(weights1_init, dtype=tf.float32, name=\"weights1\")\n",
    "weights2 = tf.Variable(weights2_init, dtype=tf.float32, name=\"weights2\")\n",
    "weights3 = tf.transpose(weights2, name=\"weights3\")  # weight2를 전치 \n",
    "weights4 = tf.transpose(weights1, name=\"weights4\")  # weight1을 전치 \n",
    "\n",
    "#bias\n",
    "biases1 = tf.Variable(tf.zeros(n_hidden1), name=\"biases1\")\n",
    "biases2 = tf.Variable(tf.zeros(n_hidden2), name=\"biases2\")\n",
    "biases3 = tf.Variable(tf.zeros(n_hidden3), name=\"biases3\")\n",
    "biases4 = tf.Variable(tf.zeros(n_outputs), name=\"biases4\")\n",
    "\n",
    "hidden1 = activation(tf.matmul(X, weights1) + biases1)\n",
    "hidden2 = activation(tf.matmul(hidden1, weights2) + biases2)\n",
    "hidden3 = activation(tf.matmul(hidden2, weights3) + biases3)\n",
    "outputs = tf.matmul(hidden3, weights4) + biases4\n",
    "\n",
    "reconstruction_loss = tf.reduce_mean(tf.square(outputs - X)) #복원 loss\n",
    "reg_loss = regularizer(weights1) + regularizer(weights2)\n",
    "loss = reconstruction_loss + reg_loss #loss\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 가중치3과 가중치4는 variable이 아니고 각각 가중치2와 가중치 1을 전치한 것 (서로 묶임)\n",
    "- 둘은 variable이 아니기 때문에 제약(regularizing)을 사용하지 않음 (가중치1, 가중치2에만 사용)\n",
    "- bias는 절대 서로 묶이지 않으며 제약하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train MSE: 0.013255\n",
      "1 Train MSE: 0.00795071\n",
      "2 Train MSE: 0.0074879\n",
      "3 Train MSE: 0.00736283\n",
      "4 Train MSE: 0.00717537\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        n_batches = mnist.train.num_examples // batch_size\n",
    "        for iteration in range(n_batches):\n",
    "            print(\"\\r{}%\".format(100 * iteration // n_batches), end=\"\")\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch})\n",
    "        loss_train = reconstruction_loss.eval(feed_dict={X: X_batch})\n",
    "        print(\"\\r{}\".format(epoch), \"Train MSE:\", loss_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training One Autoencoder at a Time\n",
    "#### - 한번에 전체 stacked autoencoder를 학습하는 것보다, 얕은 autoencoder를 하나씩 학습한 후 합치는 것이 더 빠름 \n",
    "<img src = \"image\\ch15\\oneattime.png\">\n",
    "- 단계1의 학습 동안, 첫번째 autoencoder는 입력을 복원하는 것을 학습함 \n",
    "- 단계2의 학습 동안, 두번째 autoencoder는 autoencoder의 첫번째 은닉층의 출력을 복원하는 것을 학습함 \n",
    "- 최종적으로 두 단계를 쌓으면 하나의 큰 stacked autoencoder가 됨 \n",
    "\n",
    "\n",
    "#### - 다단계 알고리즘의 학습을 구현하는 방법 \n",
    "- 가장 간단한 방법은 각 단계마다 다른 tensorflow 그래프를 사용하는 것 \n",
    "    - autoencoder의 학습 후에 학습셋을 실행하고 은닉층의 출력을 포착\n",
    "    - 은닉층의 출력은 다음 autoencoder의 학습셋이 됨\n",
    "    - 모든 autoencoder이 이런 방식으로 학습되면 각 autoencoder의 가중치와 bias를 복사하여 stakced autoencoder를 생성한다 \n",
    "    \n",
    "    \n",
    "- 전체 stacked autoencoder를 포함하는 하나의 tensorflow 그래프를 사용하는 것 \n",
    "    - 각 학습 단계를 수행하기 위해 추가적인 동작이 필요 \n",
    "<img src = \"image\\ch15\\stackedae2.png\">\n",
    "- 중앙은 전체 stacked encoder로, 학습 후에 사용 \n",
    "- 왼쪽 \n",
    "    - 학습의 단계1에서 수행되어야 할 동작 \n",
    "    - 은닉층2와 은닉층3을 우회하여 출력을 생성 \n",
    "    - 단계1의 가중치와 bias는 stacked autoencoder의 출력층과 동일 \n",
    "    - 목표는 입력과 출력을 최대한 비슷하게 만드는 것 \n",
    "    - 이 autoencoder는 은닉층1과 출력층에 대한 가중치와 bias를 학습 \n",
    "    \n",
    "\n",
    "\n",
    "- 오른쪽 \n",
    "    - 학습의 단계2에서 수행되어야 할 동작 \n",
    "    - 목표는 은닉층3의 출력이 은닉층1의 출력과 최대한 비슷하게 만드는 것 \n",
    "    - 단계2의 학습동안 은닉층1의 파라미터는 고정(동결)시켜야 함 \n",
    "    - 이 autoencoder는 은닉층2와 은닉층3에 대한 가중치와 bias를 학습 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 150  # codings\n",
    "n_hidden3 = n_hidden1\n",
    "n_outputs = n_inputs\n",
    "\n",
    "learning_rate = 0.01\n",
    "l2_reg = 0.0001\n",
    "\n",
    "activation = tf.nn.elu\n",
    "regularizer = tf.contrib.layers.l2_regularizer(l2_reg)\n",
    "initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_inputs])\n",
    "\n",
    "#가중치들을 묶지 않음 \n",
    "weights1_init = initializer([n_inputs, n_hidden1])\n",
    "weights2_init = initializer([n_hidden1, n_hidden2])\n",
    "weights3_init = initializer([n_hidden2, n_hidden3])\n",
    "weights4_init = initializer([n_hidden3, n_outputs])\n",
    "\n",
    "weights1 = tf.Variable(weights1_init, dtype=tf.float32, name=\"weights1\") #입력-은닉1\n",
    "weights2 = tf.Variable(weights2_init, dtype=tf.float32, name=\"weights2\") #은닉1-은닉2\n",
    "weights3 = tf.Variable(weights3_init, dtype=tf.float32, name=\"weights3\") #은닉2-은닉3\n",
    "weights4 = tf.Variable(weights4_init, dtype=tf.float32, name=\"weights4\") #은닉3-출력\n",
    "\n",
    "biases1 = tf.Variable(tf.zeros(n_hidden1), name=\"biases1\")\n",
    "biases2 = tf.Variable(tf.zeros(n_hidden2), name=\"biases2\")\n",
    "biases3 = tf.Variable(tf.zeros(n_hidden3), name=\"biases3\")\n",
    "biases4 = tf.Variable(tf.zeros(n_outputs), name=\"biases4\")\n",
    "\n",
    "hidden1 = activation(tf.matmul(X, weights1) + biases1)\n",
    "hidden2 = activation(tf.matmul(hidden1, weights2) + biases2)\n",
    "hidden3 = activation(tf.matmul(hidden2, weights3) + biases3)\n",
    "outputs = tf.matmul(hidden3, weights4) + biases4\n",
    "\n",
    "reconstruction_loss = tf.reduce_mean(tf.square(outputs - X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "with tf.name_scope(\"phase1\"): #단계1\n",
    "    phase1_outputs = tf.matmul(hidden1, weights4) + biases4  #은닉층2과 은닉층3을 우회함 \n",
    "    phase1_reconstruction_loss = tf.reduce_mean(tf.square(phase1_outputs - X)) #목표는 출력과 입력의 차이를 최소화 \n",
    "    phase1_reg_loss = regularizer(weights1) + regularizer(weights4)\n",
    "    phase1_loss = phase1_reconstruction_loss + phase1_reg_loss\n",
    "    phase1_training_op = optimizer.minimize(phase1_loss)\n",
    "\n",
    "with tf.name_scope(\"phase2\"): #단계2\n",
    "    phase2_reconstruction_loss = tf.reduce_mean(tf.square(hidden3 - hidden1)) #목표는 은닉층3 출력과 은닉층1 출력의 차이를 최소화\n",
    "    phase2_reg_loss = regularizer(weights2) + regularizer(weights3)\n",
    "    phase2_loss = phase2_reconstruction_loss + phase2_reg_loss\n",
    "    train_vars = [weights2, biases2, weights3, biases3]\n",
    "    phase2_training_op = optimizer.minimize(phase2_loss, var_list=train_vars) #은닉층1 동결 \n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mnimize()메소드에서 학습 변수에대한 리스트를 넘김 \n",
    "    - 은닉층1의 가중치와 bias를 배제하기 위해 \n",
    "    - 단계2 학습 동안 은닉층 1을 효율적으로 동결 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training phase #1\n",
      "0 Train MSE: 0.00762054\n",
      "1 Train MSE: 0.00776723\n",
      "2 Train MSE: 0.00805012\n",
      "3 Train MSE: 0.00775856\n",
      "Training phase #2\n",
      "0 Train MSE: 0.191388\n",
      "1 Train MSE: 0.00478137\n",
      "2 Train MSE: 0.00260267\n",
      "3 Train MSE: 0.00198913\n",
      "Test MSE: 0.00974487\n"
     ]
    }
   ],
   "source": [
    "training_ops = [phase1_training_op, phase2_training_op]\n",
    "reconstruction_losses = [phase1_reconstruction_loss, phase2_reconstruction_loss]\n",
    "n_epochs = [4, 4]\n",
    "batch_sizes = [150, 150]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for phase in range(2):\n",
    "        print(\"Training phase #{}\".format(phase + 1))\n",
    "        for epoch in range(n_epochs[phase]):\n",
    "            n_batches = mnist.train.num_examples // batch_sizes[phase]\n",
    "            for iteration in range(n_batches):\n",
    "                print(\"\\r{}%\".format(100 * iteration // n_batches), end=\"\")\n",
    "                X_batch, y_batch = mnist.train.next_batch(batch_sizes[phase])\n",
    "                sess.run(training_ops[phase], feed_dict={X: X_batch})\n",
    "            loss_train = reconstruction_losses[phase].eval(feed_dict={X: X_batch})\n",
    "            print(\"\\r{}\".format(epoch), \"Train MSE:\", loss_train)\n",
    "    loss_test = reconstruction_loss.eval(feed_dict={X: mnist.test.images})\n",
    "    print(\"Test MSE:\", loss_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Reconstructions \n",
    "#### autoencoder가 잘 학습됐는지 확인을 위해 입력과 출력을 비교 \n",
    "- 잘 학습됐다면 입력과 출력은 비슷해야하고, 차이는 중요하지 않은 부분이어야 함 \n",
    "\n",
    "#### - 임의 digit(input)과 그것의 복원(reconstruction) 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value dense_6/bias\n\t [[Node: dense_6/bias/read = Identity[T=DT_FLOAT, _class=[\"loc:@dense_6/bias\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dense_6/bias)]]\n\nCaused by op 'dense_6/bias/read', defined at:\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-112-57142da338d0>\", line 30, in <module>\n    logits = my_dense_layer(hidden5, n_outputs, activation=None)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\core.py\", line 250, in dense\n    return layer.apply(inputs)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 671, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 559, in __call__\n    self.build(input_shapes[0])\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\core.py\", line 145, in build\n    trainable=True)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 458, in add_variable\n    trainable=trainable and self.trainable)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1203, in get_variable\n    constraint=constraint)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1092, in get_variable\n    constraint=constraint)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 425, in get_variable\n    constraint=constraint)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 394, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 805, in _get_single_variable\n    constraint=constraint)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 213, in __init__\n    constraint=constraint)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 356, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 125, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 2070, in identity\n    \"Identity\", input=input, name=name)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value dense_6/bias\n\t [[Node: dense_6/bias/read = Identity[T=DT_FLOAT, _class=[\"loc:@dense_6/bias\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dense_6/bias)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value dense_6/bias\n\t [[Node: dense_6/bias/read = Identity[T=DT_FLOAT, _class=[\"loc:@dense_6/bias\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dense_6/bias)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-89004011e682>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0moutputs_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m     \"\"\"\n\u001b[1;32m--> 570\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_dup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   4453\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4454\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 4455\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1334\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1336\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value dense_6/bias\n\t [[Node: dense_6/bias/read = Identity[T=DT_FLOAT, _class=[\"loc:@dense_6/bias\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dense_6/bias)]]\n\nCaused by op 'dense_6/bias/read', defined at:\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-112-57142da338d0>\", line 30, in <module>\n    logits = my_dense_layer(hidden5, n_outputs, activation=None)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\core.py\", line 250, in dense\n    return layer.apply(inputs)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 671, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 559, in __call__\n    self.build(input_shapes[0])\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\core.py\", line 145, in build\n    trainable=True)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 458, in add_variable\n    trainable=trainable and self.trainable)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1203, in get_variable\n    constraint=constraint)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1092, in get_variable\n    constraint=constraint)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 425, in get_variable\n    constraint=constraint)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 394, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 805, in _get_single_variable\n    constraint=constraint)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 213, in __init__\n    constraint=constraint)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 356, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 125, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 2070, in identity\n    \"Identity\", input=input, name=name)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value dense_6/bias\n\t [[Node: dense_6/bias/read = Identity[T=DT_FLOAT, _class=[\"loc:@dense_6/bias\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dense_6/bias)]]\n"
     ]
    }
   ],
   "source": [
    "n_test_digits = 2 #2개 \n",
    "X_test = mnist.test.images[:n_test_digits] #테스트데이터에서 2개 추출 \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    outputs_val = outputs.eval(feed_dict={X: X_test})\n",
    "\n",
    "def plot_image(image, shape=[28, 28]):\n",
    "    plt.imshow(image.reshape(shape), cmap=\"Greys\", interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "for digit_index in range(n_test_digits):\n",
    "    plt.subplot(n_test_digits, 2, digit_index * 2 + 1)\n",
    "    plot_image(X_test[digit_index])\n",
    "    plt.subplot(n_test_digits, 2, digit_index * 2 + 2)\n",
    "    plot_image(outputs_val[digit_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 충분히 비슷해보임 \n",
    "- autoencoder가 재형성을 잘 학습했음\n",
    "- 유용한 특징을 학습했는지도 확인해보자 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Features\n",
    "### - autoencoder가 어떤 특징들을 학습했는가 확인하는 방법 \n",
    "#### - 모든 은닉층의 각 뉴런을 고려하고 가장 활성화된 학습데이터를 찾는 것 \n",
    "- 상대적으로 큰 특징을 포착하는 최종 은닉층에서 특히 유용 \n",
    "- 낮은 층에서는 특징이 더 작고 추상적이기 때문에 이 방법이 잘 동작하지 않음 \n",
    "\n",
    "\n",
    "#### - 은닉층1의 각 뉴런에 대해 해당 뉴런의 연결가중치에 상응하는 픽셀강도를 가진 이미지를 생성 \n",
    "- 은닉층1의 5개 뉴런이 학습한 특징 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value weights1\n\t [[Node: _retval_weights1_0_0 = _Retval[T=DT_FLOAT, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](weights1)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value weights1\n\t [[Node: _retval_weights1_0_0 = _Retval[T=DT_FLOAT, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](weights1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-0f6490506714>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mweights1_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, session)\u001b[0m\n\u001b[0;32m    508\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mvariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     \"\"\"\n\u001b[1;32m--> 510\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0minitialized_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m     \"\"\"\n\u001b[1;32m--> 570\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_dup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   4453\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4454\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 4455\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1334\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1336\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value weights1\n\t [[Node: _retval_weights1_0_0 = _Retval[T=DT_FLOAT, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](weights1)]]"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    weights1_val = weights1.eval()\n",
    "\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plot_image(weights1_val.T[i])\n",
    "\n",
    "plt.show()                          # not shown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"image\\ch15\\feature.png\">\n",
    "- 앞 네개의 특징은 작은 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 임의의 입력영상을 autoencoder에 전달, 관심있는 뉴런의 활성화 측정, 그 뉴런이 더 활성화되는 방법으로 이미지를 수정해서 역전파\n",
    "- 몇 번 반복하면 이미지는 뉴런이 최대로 활성화된 영상이 됨 \n",
    "- 뉴런이 찾고있는 입력을 시각화하는데 유용한 방법 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Pretraining Using Stacked Autoencoders\n",
    "#### 복잡한 지도학습 수행 중 충분한 양의 라벨화된 데이터가 없을 경우, 비슷한 수행을 하는 신경망을 찾고 그 신경망의 낮은 레이어들을 활용함 \n",
    "\n",
    "### - 분류 신경망을 위한 비지도 선행학습을 수행에 stacked autoencoder를 사용하는 방법 \n",
    "<img src = \"image\\ch15\\pretrain.png\">\n",
    "- 모든 학습데이터를 사용해 autoencoder를 학습 \n",
    "- enncoder레이어를 재사용하여 새로운 신경망 생성 \n",
    "\n",
    "- autoencoder가 유용한 특징을 학습하도록 하기 위해서는 coding레이어의 크기를 제한(입력레이어보다 적게)하면 됨 \n",
    "    - 다른 제약들도 존재 \n",
    "        - coding레이어의 크기를 입력레이어의 크기와 똑같이 \n",
    "        - coding레이어의 크기를 입력레이어의 크기보다 크게(overcomplete autoencoder)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising Autoencoders\n",
    "#### 노이즈를 입력에 추가하여 출력은 원본을 복원하도록 학습 \n",
    "- autoencoder가 유용한 특징을 학습하도록 만들기 위해 \n",
    "<img src = \"image\\ch15\\denosing.png\">\n",
    "- 노이즈\n",
    "    - 입력데이터에 추가된 gaussian 노이즈 \n",
    "    - dropout을 통해 입력들을 임의로 무시 \n",
    "    \n",
    "### Tensorflow Implementation\n",
    "#### - 가우시안 노이즈를 사용한 denosing autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 150  # codings\n",
    "n_hidden3 = n_hidden1\n",
    "n_outputs = n_inputs\n",
    "\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise_level = 1.0\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_inputs])\n",
    "X_noisy = X + noise_level * tf.random_normal(tf.shape(X))\n",
    "\n",
    "hidden1 = tf.layers.dense(X_noisy, n_hidden1, activation=tf.nn.relu,\n",
    "                          name=\"hidden1\")\n",
    "hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, \n",
    "                          name=\"hidden2\")                            \n",
    "hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu,\n",
    "                          name=\"hidden3\")                            \n",
    "outputs = tf.layers.dense(hidden3, n_outputs, name=\"outputs\")        \n",
    "\n",
    "reconstruction_loss = tf.reduce_mean(tf.square(outputs - X)) # MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(reconstruction_loss)\n",
    "    \n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train MSE: 0.0458874\n",
      "1 Train MSE: 0.0441232\n",
      "2 Train MSE: 0.0425017\n",
      "3 Train MSE: 0.045178\n",
      "4 Train MSE: 0.0441855\n",
      "5 Train MSE: 0.0443099\n",
      "6 Train MSE: 0.04394\n",
      "7 Train MSE: 0.0437239\n",
      "8 Train MSE: 0.0429857\n",
      "9 Train MSE: 0.0438221\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        n_batches = mnist.train.num_examples // batch_size\n",
    "        for iteration in range(n_batches):\n",
    "            print(\"\\r{}%\".format(100 * iteration // n_batches), end=\"\")\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch})\n",
    "        loss_train = reconstruction_loss.eval(feed_dict={X: X_batch})\n",
    "        print(\"\\r{}\".format(epoch), \"Train MSE:\", loss_train)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - dropout을 사용한 denoising autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 150  # codings\n",
    "n_hidden3 = n_hidden1\n",
    "n_outputs = n_inputs\n",
    "\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropout_rate = 0.3\n",
    "\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_inputs])\n",
    "X_drop = tf.layers.dropout(X, dropout_rate, training=training)\n",
    "\n",
    "hidden1 = tf.layers.dense(X_drop, n_hidden1, activation=tf.nn.relu,\n",
    "                          name=\"hidden1\")\n",
    "hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, # not shown in the book\n",
    "                          name=\"hidden2\")                            # not shown\n",
    "hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, # not shown\n",
    "                          name=\"hidden3\")                            # not shown\n",
    "outputs = tf.layers.dense(hidden3, n_outputs, name=\"outputs\")        # not shown\n",
    "\n",
    "reconstruction_loss = tf.reduce_mean(tf.square(outputs - X)) # MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(reconstruction_loss)\n",
    "    \n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train MSE: 0.0306857\n",
      "1 Train MSE: 0.0272023\n",
      "2 Train MSE: 0.0254226\n",
      "3 Train MSE: 0.0257622\n",
      "4 Train MSE: 0.0243549\n",
      "5 Train MSE: 0.024227\n",
      "6 Train MSE: 0.0246143\n",
      "7 Train MSE: 0.023919\n",
      "8 Train MSE: 0.0241766\n",
      "9 Train MSE: 0.0243544\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        n_batches = mnist.train.num_examples // batch_size\n",
    "        for iteration in range(n_batches):\n",
    "            print(\"\\r{}%\".format(100 * iteration // n_batches), end=\"\")\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, training: True})\n",
    "        loss_train = reconstruction_loss.eval(feed_dict={X: X_batch})\n",
    "        print(\"\\r{}\".format(epoch), \"Train MSE:\", loss_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Autoencoders\n",
    "#### 희소성(sparsity)를 통해 autoencoder가 좋은 특징을 학습하도록 만든다 \n",
    "- 비용함수에 적절한 항을 추가해 autoencoder가 coding레이어의 활성화 뉴런 개수를 줄이도록 함 \n",
    "    - 결과적으로 coding레이어의 각 뉴런은 보통 유용한 특징을 재형성하게 됨 \n",
    "        - 예) 한 달에 몇 마디의 말만 할 수 있다면 들을 가치가 있을만한 말을 할 것 \n",
    "        \n",
    "\n",
    "- sparse 모델을 위해서는 먼저 각 학습 반복마다 coding레이어의 실제 희소성을 측정해야함 \n",
    "    - 전체 훈련 데이터 batch에 대해 coding레이어의 각 뉴런의 평균 활성화를 계산 \n",
    "        - batch의 크기가 너무 작으면 평균이 정확하지 않을 수 있음 \n",
    "   \n",
    "   \n",
    "- 지나치게 활성화된 뉴런을 비용함수에 sparsity loss를 통해서 처벌을 줌 \n",
    "    - ( 0.1의 희소성을 기대했을 때, 어떤 뉴런의 평균 활성화 정도가 0.3이면)\n",
    "    - 간단하게 제곱오차를 사용할 수도 있음 \n",
    "    - 하지만 MSE보다 더 강력한 기울기를 가지는 Kullback-Leilbler 분산을 사용하는 것이 더 좋음 \n",
    "    \n",
    "### - Kullback-Leibler divegence\n",
    "<img src = \"image\\ch15\\dkl.png\">\n",
    "- 두 확률분포의 차이를 계산할 때 사용\n",
    "- 우리는 coding레이어의 뉴런의 목표 활성화정도 p(0.1), 실제 활성화 정도 q(0.3)에 대한 kld를 측정 \n",
    "\n",
    "<img src = \"image\\ch15\\dkl2.png\">\n",
    "\n",
    "\n",
    "#### \n",
    "- coding레이어의 각 뉴런데 대한 sparsity loss를 계산하고 모두 더한 것을 비용함수에 더함 \n",
    "- sparsity loss와 복원 loss에 대한 상대중요도는 aprsity 가중치 하이퍼파라미터를 통해 조절 가능 \n",
    "    - 가중치가 너무 높으면 모델은 목표 sparsity에 가까워지지만 입력을 잘 복원하지는 못함 \n",
    "    - 가중치가 너무 낮으면 모델은 sparsity를 거의 무시하면서 유용한 특징을 학습하지 못하게 됨 \n",
    "    \n",
    "    \n",
    "### Tensorflow Implementation \n",
    "#### - Tensorflow로 sparse autoencoder 구현 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 1000  # sparse codings\n",
    "n_outputs = n_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kl_divergence(p, q):\n",
    "    # Kullback Leibler divergence\n",
    "    return p * tf.log(p / q) + (1 - p) * tf.log((1 - p) / (1 - q))\n",
    "\n",
    "learning_rate = 0.01\n",
    "sparsity_target = 0.1\n",
    "sparsity_weight = 0.2\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_inputs])            # not shown in the book\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.sigmoid) # not shown\n",
    "outputs = tf.layers.dense(hidden1, n_outputs)                     # not shown\n",
    "\n",
    "hidden1_mean = tf.reduce_mean(hidden1, axis=0) # batch mean\n",
    "sparsity_loss = tf.reduce_sum(kl_divergence(sparsity_target, hidden1_mean))\n",
    "reconstruction_loss = tf.reduce_mean(tf.square(outputs - X)) # MSE\n",
    "loss = reconstruction_loss + sparsity_weight * sparsity_loss\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train MSE: 0.136955 \tSparsity loss: 0.436191 \tTotal loss: 0.224193\n",
      "1 Train MSE: 0.0580629 \tSparsity loss: 0.0964747 \tTotal loss: 0.0773579\n",
      "2 Train MSE: 0.0528143 \tSparsity loss: 0.0899125 \tTotal loss: 0.0707968\n",
      "3 Train MSE: 0.0470392 \tSparsity loss: 0.0492329 \tTotal loss: 0.0568858\n",
      "4 Train MSE: 0.0442649 \tSparsity loss: 0.103844 \tTotal loss: 0.0650337\n",
      "5 Train MSE: 0.0411107 \tSparsity loss: 0.297899 \tTotal loss: 0.100691\n",
      "6 Train MSE: 0.0384743 \tSparsity loss: 0.0493214 \tTotal loss: 0.0483386\n",
      "7 Train MSE: 0.0356063 \tSparsity loss: 0.0809253 \tTotal loss: 0.0517913\n",
      "8 Train MSE: 0.034265 \tSparsity loss: 0.0531838 \tTotal loss: 0.0449018\n",
      "9 Train MSE: 0.0308278 \tSparsity loss: 0.0215698 \tTotal loss: 0.0351418\n",
      "10 Train MSE: 0.0264248 \tSparsity loss: 0.317476 \tTotal loss: 0.08992\n",
      "11 Train MSE: 0.0252795 \tSparsity loss: 0.104245 \tTotal loss: 0.0461284\n",
      "12 Train MSE: 0.0238557 \tSparsity loss: 0.0620825 \tTotal loss: 0.0362722\n",
      "13 Train MSE: 0.0222615 \tSparsity loss: 0.0257412 \tTotal loss: 0.0274097\n",
      "14 Train MSE: 0.0213349 \tSparsity loss: 0.0978729 \tTotal loss: 0.0409095\n",
      "15 Train MSE: 0.0209322 \tSparsity loss: 0.109286 \tTotal loss: 0.0427894\n",
      "16 Train MSE: 0.019222 \tSparsity loss: 0.0708527 \tTotal loss: 0.0333925\n",
      "17 Train MSE: 0.019766 \tSparsity loss: 0.160146 \tTotal loss: 0.0517953\n",
      "18 Train MSE: 0.0195028 \tSparsity loss: 0.219796 \tTotal loss: 0.0634621\n",
      "19 Train MSE: 0.0176975 \tSparsity loss: 0.0528596 \tTotal loss: 0.0282694\n",
      "20 Train MSE: 0.015937 \tSparsity loss: 0.334839 \tTotal loss: 0.0829047\n",
      "21 Train MSE: 0.0160815 \tSparsity loss: 0.0372252 \tTotal loss: 0.0235265\n",
      "22 Train MSE: 0.0158617 \tSparsity loss: 0.108462 \tTotal loss: 0.0375542\n",
      "23 Train MSE: 0.0152926 \tSparsity loss: 0.163531 \tTotal loss: 0.0479988\n",
      "24 Train MSE: 0.015498 \tSparsity loss: 0.046527 \tTotal loss: 0.0248034\n",
      "25 Train MSE: 0.0146435 \tSparsity loss: 0.046302 \tTotal loss: 0.0239039\n",
      "26 Train MSE: 0.0146764 \tSparsity loss: 0.100147 \tTotal loss: 0.0347058\n",
      "27 Train MSE: 0.0146198 \tSparsity loss: 0.0336003 \tTotal loss: 0.0213399\n",
      "28 Train MSE: 0.0160601 \tSparsity loss: 0.264054 \tTotal loss: 0.0688709\n",
      "16%"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-a38754fd8020>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\r{}%\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mn_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mreconstruction_loss_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparsity_loss_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreconstruction_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparsity_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\r{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Train MSE:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreconstruction_loss_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\tSparsity loss:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparsity_loss_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\tTotal loss:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 1000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        n_batches = mnist.train.num_examples // batch_size\n",
    "        for iteration in range(n_batches):\n",
    "            print(\"\\r{}%\".format(100 * iteration // n_batches), end=\"\")\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch})\n",
    "        reconstruction_loss_val, sparsity_loss_val, loss_val = sess.run([reconstruction_loss, sparsity_loss, loss], feed_dict={X: X_batch})\n",
    "        print(\"\\r{}\".format(epoch), \"Train MSE:\", reconstruction_loss_val, \"\\tSparsity loss:\", sparsity_loss_val, \"\\tTotal loss:\", loss_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- coding레이어의 활성화는 반드시 0과 1 사이어야 함 \n",
    "    - 아니라면 KL분산은 NaN을 반환 \n",
    "    - 간단한 해결방법 : coding레이어에서 로지스틱 활성화 함수를 사용\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 수렴을 빠르게 하는 간단한 방법 \n",
    "    - 복원 loss를 MSE보다 기울기가 더 큰 것을 사용 \n",
    "        - cross entropy \n",
    "        - : 입력을 0과 1사이에 위치하도록 정규화 \n",
    "        - 출력층에서 로지스틱 활성화를 사용해 출력값도 0~1이 나오도록 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits = tf.layers.dense(hidden1, n_outputs)\n",
    "outputs = tf.nn.sigmoid(logits)\n",
    "\n",
    "xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=X, logits=logits)\n",
    "reconstruction_loss = tf.reduce_mean(xentropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- outputs는 학습동안은 사용되지 않음 (복원을 보고 싶을때만 사용)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoders\n",
    "### - 다른 autoencoder와 차이점 \n",
    "#### - 확률적인 autoencoder : 출력은 부분적으로 우연에 의해 결정(학습 후에도)\n",
    "#### - generative autoencoder : 학습데이터로부터 샘플된 것 같은 새로운 데이터를 생성할 수 있음 \n",
    "\n",
    "### - 구조 \n",
    "<img src = \"image\\ch15\\vae.png\">\n",
    "- 다른 autoencoder들과 같이 encoder 다음에는 decoder가 위치함 \n",
    "    - 하지만 입력에 대한 coding을 바로 생산하는 것이 아니라 encoder는 coding의 평균 μ와 표준편차 σ를 생산 \n",
    "    - 실제 coding은 평균과 표준편차에 대한 가우시안 분산에서 임의로 샘플링됨 \n",
    "        - 샘플링 : 그 확률 분포를 따르는 빈도로 새로운 샘플(데이터)를 만들어 내는 것 \n",
    "    - decoder는 샘플된 coding을 decoding함 \n",
    "    \n",
    "    \n",
    " \n",
    "- 오른쪽 \n",
    "    - 학습데이터가 autoencoder를 통과하는 과정 \n",
    "        - eocoder가 평균과 표준편차를 생산 \n",
    "        - coding은 임의로 샘플링됨 (평균과 똑같은 위치에 존재하지 않음)\n",
    "        - 샘플링된 coding이 decoding되고 최종 출력은 학습 데이터와 유사 \n",
    "        \n",
    "        \n",
    "        \n",
    "- 입력은 보통 복잡한 분산을 가지지만, variational autoencoder는 coding이 간단한 가우시안 분포로부터 샘플링 함\n",
    "    - 학습 동안 비용함수는 가우시안 점들의 구름처럼 보이는 구형영역을 차지하도록 coding들을 coding영역에 점차적으로 밀어 넣는다..?\n",
    "    \n",
    "    \n",
    "\n",
    "#### - variational autoencoder는 학습 후에 새로운 데이터를 쉽게 생성할 수 있음 \n",
    "- 가우시안 분산으로 부터 임의 coding을 샘플링한 후 decoding\n",
    "\n",
    "\n",
    "#### - 비용함수 \n",
    "- 복원 loss \n",
    "    - 입력 복원에 대한 loss (cross entropy 사용)\n",
    "   \n",
    "   \n",
    "- latent loss\n",
    "    - autoencoder가 간단한 가우시안 분포로 부터 샘플링된 coding을 가지도록 \n",
    "    - 가우시안분포와 실제 분포의 KL분산 사용 \n",
    "    - 가우시안 노이즈는 coding레이어로 전송되는 정보의 양을 제한하기 때문에 수학적으로 조금 더 복잡하지만 유용한 특징을 학습할 수 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 500\n",
    "n_hidden2 = 500\n",
    "n_hidden3 = 20  # codings\n",
    "n_hidden4 = n_hidden2\n",
    "n_hidden5 = n_hidden1\n",
    "n_outputs = n_inputs\n",
    "learning_rate = 0.001\n",
    "\n",
    "initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "my_dense_layer = partial(\n",
    "    tf.layers.dense,\n",
    "    activation=tf.nn.elu,\n",
    "    kernel_initializer=initializer)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "hidden1 = my_dense_layer(X, n_hidden1)\n",
    "hidden2 = my_dense_layer(hidden1, n_hidden2)\n",
    "hidden3_mean = my_dense_layer(hidden2, n_hidden3, activation=None)\n",
    "hidden3_sigma = my_dense_layer(hidden2, n_hidden3, activation=None)\n",
    "noise = tf.random_normal(tf.shape(hidden3_sigma), dtype=tf.float32)\n",
    "hidden3 = hidden3_mean + hidden3_sigma * noise\n",
    "hidden4 = my_dense_layer(hidden3, n_hidden4)\n",
    "hidden5 = my_dense_layer(hidden4, n_hidden5)\n",
    "logits = my_dense_layer(hidden5, n_outputs, activation=None)\n",
    "outputs = tf.sigmoid(logits)\n",
    "\n",
    "xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=X, logits=logits)\n",
    "reconstruction_loss = tf.reduce_sum(xentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eps = 1e-10 # smoothing term to avoid computing log(0) which is NaN\n",
    "latent_loss = 0.5 * tf.reduce_sum(\n",
    "    tf.square(hidden3_sigma) + tf.square(hidden3_mean)\n",
    "    - 1 - tf.log(eps + tf.square(hidden3_sigma)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = reconstruction_loss + latent_loss\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        n_batches = mnist.train.num_examples // batch_size\n",
    "        for iteration in range(n_batches):\n",
    "            print(\"\\r{}%\".format(100 * iteration // n_batches), end=\"\")\n",
    "            \n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch})\n",
    "        loss_val, reconstruction_loss_val, latent_loss_val = sess.run([loss, reconstruction_loss, latent_loss], feed_dict={X: X_batch})\n",
    "        print(\"\\r{}\".format(epoch), \"Train total loss:\", loss_val, \"\\tReconstruction loss:\", reconstruction_loss_val, \"\\tLatent loss:\", latent_loss_val)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 500\n",
    "n_hidden2 = 500\n",
    "n_hidden3 = 20  # codings\n",
    "n_hidden4 = n_hidden2\n",
    "n_hidden5 = n_hidden1\n",
    "n_outputs = n_inputs\n",
    "learning_rate = 0.001\n",
    "\n",
    "initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "my_dense_layer = partial(\n",
    "    tf.layers.dense,\n",
    "    activation=tf.nn.elu,\n",
    "    kernel_initializer=initializer)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "hidden1 = my_dense_layer(X, n_hidden1)\n",
    "hidden2 = my_dense_layer(hidden1, n_hidden2)\n",
    "hidden3_mean = my_dense_layer(hidden2, n_hidden3, activation=None)\n",
    "hidden3_gamma = my_dense_layer(hidden2, n_hidden3, activation=None)\n",
    "noise = tf.random_normal(tf.shape(hidden3_gamma), dtype=tf.float32)\n",
    "hidden3 = hidden3_mean + tf.exp(0.5 * hidden3_gamma) * noise\n",
    "hidden4 = my_dense_layer(hidden3, n_hidden4)\n",
    "hidden5 = my_dense_layer(hidden4, n_hidden5)\n",
    "logits = my_dense_layer(hidden5, n_outputs, activation=None)\n",
    "outputs = tf.sigmoid(logits)\n",
    "\n",
    "xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=X, logits=logits)\n",
    "reconstruction_loss = tf.reduce_sum(xentropy)\n",
    "latent_loss = 0.5 * tf.reduce_sum(\n",
    "    tf.exp(hidden3_gamma) + tf.square(hidden3_mean) - 1 - hidden3_gamma)\n",
    "loss = reconstruction_loss + latent_loss\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Digits\n",
    "#### 손으로 쓴 숫자처럼 보이는 영상을 variational autoencoder를 통해 생성해보자 \n",
    "- 모델을 학습시키고 가우시안 분포로부터 임의의 coding들을 샘플링하고 decoding한다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train total loss: 36962.2 \tReconstruction loss: 25520.6 \tLatent loss: 11441.6\n",
      "1 Train total loss: 32333.9 \tReconstruction loss: 23674.9 \tLatent loss: 8659.0\n",
      "2 Train total loss: 24286.4 \tReconstruction loss: 20925.5 \tLatent loss: 3360.9\n",
      "3 Train total loss: 28864.3 \tReconstruction loss: 23606.9 \tLatent loss: 5257.39\n",
      "4 Train total loss: 26798.0 \tReconstruction loss: 22136.6 \tLatent loss: 4661.41\n",
      "5 Train total loss: 21896.5 \tReconstruction loss: 18597.6 \tLatent loss: 3298.87\n",
      "6 Train total loss: 21896.3 \tReconstruction loss: 17175.5 \tLatent loss: 4720.76\n",
      "7 Train total loss: 17896.9 \tReconstruction loss: 15054.5 \tLatent loss: 2842.39\n",
      "8 Train total loss: 18699.7 \tReconstruction loss: 15543.1 \tLatent loss: 3156.65\n",
      "9 Train total loss: 16756.2 \tReconstruction loss: 13605.3 \tLatent loss: 3150.89\n",
      "10 Train total loss: 16799.3 \tReconstruction loss: 13547.6 \tLatent loss: 3251.63\n",
      "11 Train total loss: 16395.8 \tReconstruction loss: 13211.9 \tLatent loss: 3183.9\n",
      "12 Train total loss: 16432.9 \tReconstruction loss: 13341.1 \tLatent loss: 3091.76\n",
      "13 Train total loss: 16322.0 \tReconstruction loss: 13060.2 \tLatent loss: 3261.83\n",
      "14 Train total loss: 17593.5 \tReconstruction loss: 14022.6 \tLatent loss: 3570.82\n",
      "15 Train total loss: 20007.7 \tReconstruction loss: 16241.4 \tLatent loss: 3766.29\n",
      "16 Train total loss: 16903.0 \tReconstruction loss: 13518.3 \tLatent loss: 3384.66\n",
      "17 Train total loss: 17223.6 \tReconstruction loss: 13711.2 \tLatent loss: 3512.46\n",
      "18 Train total loss: 16257.0 \tReconstruction loss: 12858.1 \tLatent loss: 3398.89\n",
      "19 Train total loss: 15898.8 \tReconstruction loss: 12463.6 \tLatent loss: 3435.22\n",
      "20 Train total loss: 27127.6 \tReconstruction loss: 21385.7 \tLatent loss: 5741.84\n",
      "21 Train total loss: 32755.4 \tReconstruction loss: 26412.4 \tLatent loss: 6342.97\n",
      "22 Train total loss: 23004.6 \tReconstruction loss: 19662.8 \tLatent loss: 3341.79\n",
      "23 Train total loss: 26510.5 \tReconstruction loss: 22055.6 \tLatent loss: 4454.92\n",
      "24 Train total loss: 21167.9 \tReconstruction loss: 17744.1 \tLatent loss: 3423.86\n",
      "25 Train total loss: 18266.7 \tReconstruction loss: 15033.1 \tLatent loss: 3233.67\n",
      "26 Train total loss: 16922.1 \tReconstruction loss: 13818.1 \tLatent loss: 3103.98\n",
      "27 Train total loss: 16462.4 \tReconstruction loss: 13267.4 \tLatent loss: 3195.1\n",
      "28 Train total loss: 16507.9 \tReconstruction loss: 13158.6 \tLatent loss: 3349.26\n",
      "29 Train total loss: 15831.5 \tReconstruction loss: 12638.4 \tLatent loss: 3193.11\n",
      "30 Train total loss: 16147.6 \tReconstruction loss: 12874.4 \tLatent loss: 3273.16\n",
      "31 Train total loss: 15379.9 \tReconstruction loss: 12060.9 \tLatent loss: 3319.04\n",
      "32 Train total loss: 15462.3 \tReconstruction loss: 12213.9 \tLatent loss: 3248.43\n",
      "33 Train total loss: 18623.6 \tReconstruction loss: 15046.8 \tLatent loss: 3576.88\n",
      "34 Train total loss: 16196.3 \tReconstruction loss: 12806.4 \tLatent loss: 3389.85\n",
      "35 Train total loss: 15709.8 \tReconstruction loss: 12088.9 \tLatent loss: 3620.89\n",
      "36 Train total loss: 17173.9 \tReconstruction loss: 13820.8 \tLatent loss: 3353.15\n",
      "37 Train total loss: 15811.4 \tReconstruction loss: 12221.4 \tLatent loss: 3590.02\n",
      "38 Train total loss: 15651.6 \tReconstruction loss: 12375.4 \tLatent loss: 3276.15\n",
      "39 Train total loss: 15759.6 \tReconstruction loss: 12181.2 \tLatent loss: 3578.38\n",
      "40 Train total loss: 17184.8 \tReconstruction loss: 13990.7 \tLatent loss: 3194.04\n",
      "41 Train total loss: 17190.3 \tReconstruction loss: 13614.1 \tLatent loss: 3576.23\n",
      "42 Train total loss: 15138.1 \tReconstruction loss: 11905.6 \tLatent loss: 3232.54\n",
      "43 Train total loss: 16775.8 \tReconstruction loss: 13227.4 \tLatent loss: 3548.4\n",
      "44 Train total loss: 15946.5 \tReconstruction loss: 12821.5 \tLatent loss: 3125.01\n",
      "45 Train total loss: 15696.0 \tReconstruction loss: 12328.7 \tLatent loss: 3367.29\n",
      "46 Train total loss: 15544.7 \tReconstruction loss: 12197.8 \tLatent loss: 3346.92\n",
      "47 Train total loss: 15542.9 \tReconstruction loss: 12210.1 \tLatent loss: 3332.83\n",
      "48 Train total loss: 23199.3 \tReconstruction loss: 18458.8 \tLatent loss: 4740.5\n",
      "49 Train total loss: 15467.8 \tReconstruction loss: 12169.9 \tLatent loss: 3297.91\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_digits = 60\n",
    "n_epochs = 50\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        n_batches = mnist.train.num_examples // batch_size\n",
    "        for iteration in range(n_batches):\n",
    "            print(\"\\r{}%\".format(100 * iteration // n_batches), end=\"\") # not shown in the book\n",
    "\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch})\n",
    "        loss_val, reconstruction_loss_val, latent_loss_val = sess.run([loss, reconstruction_loss, latent_loss], feed_dict={X: X_batch}) # not shown\n",
    "        print(\"\\r{}\".format(epoch), \"Train total loss:\", loss_val, \"\\tReconstruction loss:\", reconstruction_loss_val, \"\\tLatent loss:\", latent_loss_val)  # not shown\n",
    "        \n",
    "    \n",
    "    codings_rnd = np.random.normal(size=[n_digits, n_hidden3])\n",
    "    outputs_val = outputs.eval(feed_dict={hidden3: codings_rnd})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-9d2750de2c44>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_digits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_digits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mplot_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_image' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEUAAABJCAYAAABrT+tSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAAjNJREFUeJzt2zFrFFEYheH3GEmT2koFFSQhpSuW1rGyNbWQyh/gH7HZ\nItgplhYBWxsLN4UQESHaGBsReyXwWRghwQN7s87sTsJ5YItdhuHjZfbuXphRVREnXVj0AEOUKEai\nGIliJIqRKMbUKJK2JX2TtDePgYag5Up5Cmz0PMegTI1SVa+BH3OYZTCyphgXuzqRpC1gC2BlZWW0\ntrbW1ak7sbu7+72qLjUdXFVTX8A1YK/l2KpiNBrV0ACTapw/Xx+j5Sf5GfAGWJV0IOlh/2Mt1tQ1\npao25zHIkOTrYySKkShGohiJYiSKkShGohiJYiSKkShGohiJYiSKkShGohiJYiSKkShGohiJYiSK\nkShGohiJYiSKkShGohiJYjRFkbQh6aOkfUmP+x5q0VruT1kCngD3gHVgU9J634MtUsuVcgfYr6rP\nVfULeA7c73esxWqJchn4cuz9wdFn51Yvd0cCPwd4h/Zq64EtUb4CV4+9v3L02QlVNQbGAJImVXW7\ndYh5kDRpPbbl6/MWuCnpuqRl4AHwctbhzoKWGwEPJT0CXgFLwHZVve99sgVqWlOqagfYOcV5x7ON\n06vmmVR52vQf+ZtvdBpliNuBmR7iar2Jf9qLP4vwJ+AGsAy8A9a7Ov9/zHUXuMUpHrjo8koZ5Hag\nZniIq8so52Y7kIXW6DJK03bgLOgyyrnZDnQWpaoOgb/bgQ/AiyFsB2Z5iCv/aI0stEaiGIliJIqR\nKEaiGIliJIrxGzrDFd9L16RgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1dbbe068e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,50)) # not shown in the book\n",
    "for iteration in range(n_digits):\n",
    "    plt.subplot(n_digits, 10, iteration + 1)\n",
    "    plot_image(outputs_val[iteration])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 숫자들의 대부분은 꽤 신빙성이 있지만 몇 개는 창의적 \n",
    "- autoencoder는 학습을 한 지 한시간도 안되었기 때문에 더 나은 성능을 충분히 기대할 수 있음 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Autoencoders\n",
    "- 새로운 autoencoder의 구조나 다른 비지도학습 알고리즘들도 정기적으로 등장하는 중 \n",
    "### - 다른 종류의 autoencoder들에 대한 간략한 개요 \n",
    "#### - Contractive autoencoder\n",
    "- autoencoder는 학습중에 입력과 관련된 coding의 부산물을 찾도록 학습됨 \n",
    "- 두개의 비슷한 입력은 반드시 비슷한 coding을 가짐 \n",
    "\n",
    "\n",
    "#### - Stacked convolutional autoencoders\n",
    "- convolutional 레이어를 통해 영상을 복원하여 시각 특징을 추출하도록 autoencoder를 학습 \n",
    "\n",
    "#### - Generative stochastic network\n",
    "- 데이터 생성 기능이 추가된 일반화된 denosing autoencoder\n",
    "\n",
    "#### - Winner-take-all autoencoder\n",
    "- 학습 중에, coding레이어의 모든 뉴런의 활성화를 계산\n",
    "- 학습 batch에 대해 상위 k%의 활성화를 가진 뉴런만 보존, 나머지는 0으로 설정 (자연스럽게 sparse coding이 됨)\n",
    "- 비슷한 WTA는 sparse convolutional autoencoder를 생산하는데 사용할 수 있음 \n",
    "\n",
    "\n",
    "#### - Adversarial autoencoders\n",
    "- 한 망을 입력 재생산하도록 학습, 동시에 다른 망은 첫번째 망이 제대로 복원할 수 없는 입력을 찾음 \n",
    "    - 첫번째 autoencoder가 탄탄한 coding을 학습할 수 있도록 함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
